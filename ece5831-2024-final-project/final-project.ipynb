{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8422e20253ec7f2a",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f357e246fa06741",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "278f143d53c94ae5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:07.057578Z",
     "start_time": "2024-12-16T15:44:02.423209Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d6e975025a11cb",
   "metadata": {},
   "source": [
    "## QB Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558638a4eec23854",
   "metadata": {},
   "source": [
    "#### Import and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:07.072852Z",
     "start_time": "2024-12-16T15:44:07.065297Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp = \"QB data.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc34746f850b9e84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:07.276019Z",
     "start_time": "2024-12-16T15:44:07.262510Z"
    }
   },
   "outputs": [],
   "source": [
    "def prep(file_path):\n",
    "    \n",
    "    df_list = []\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        df = pd.read_excel(xls, sheet_name=sheet_name, nrows=25)\n",
    "        df['Year'] = sheet_name\n",
    "        df_list.append(df)\n",
    "    new = pd.concat(df_list, ignore_index=True)\n",
    "    # print(new)\n",
    "    return new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d12156a5d0b3f7e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:08.830424Z",
     "start_time": "2024-12-16T15:44:07.294471Z"
    }
   },
   "outputs": [],
   "source": [
    "all = prep(fp)\n",
    "all['Awards'] = all['Awards'].apply(lambda x: x[2] if isinstance(x, str) and len(x) >= 3 else \"\")\n",
    "all['Year'] = all['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc19c9c3066b7c0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:08.876863Z",
     "start_time": "2024-12-16T15:44:08.864137Z"
    }
   },
   "outputs": [],
   "source": [
    "Train = all[all['Year'].apply(lambda x: str(x)[-1] not in ['0', '5'])]\n",
    "Test = all[all['Year'].apply(lambda x: str(x)[-1] in ['0', '5'])]\n",
    "\n",
    "X_train = Train.drop(columns=['Rk', 'Player', 'Team', 'Conf', 'Awards'], axis=1)\n",
    "Y_train = Train['Rk']\n",
    "\n",
    "X_test_name = Test['Player']\n",
    "X_test_year = Test['Year']\n",
    "X_test = Test.drop(columns=['Rk', 'Player', 'Team', 'Conf', 'Awards'], axis=1)\n",
    "Y_test = Test['Rk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24998132c25fe928",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:08.939598Z",
     "start_time": "2024-12-16T15:44:08.927352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75           Mac Jones*\n",
      "76          Kyle Trask*\n",
      "77         Zach Wilson*\n",
      "78          Sam Howell*\n",
      "79      Dillon Gabriel*\n",
      "             ...       \n",
      "720          Mike Fouts\n",
      "721         Patrick Nix\n",
      "722    Mark Butterfield\n",
      "723           Mike Groh\n",
      "724       Tony Graziani\n",
      "Name: Player, Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b69d89f0a4fe43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:09.001766Z",
     "start_time": "2024-12-16T15:44:08.989282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      G  Cmp  Att  Cmp%   Yds  TD   TD%  Int  Int%   Y/A   AY/A   Y/C    Y/G  \\\n",
      "0    15  363  555  65.4  4903  36   6.5   11   2.0   8.8   9.24  13.5  326.9   \n",
      "1    14  364  470  77.4  4508  45   9.6    3   0.6   9.6  11.22  12.4  322.0   \n",
      "2    14  302  417  72.4  3941  24   5.8    6   1.4   9.5   9.95  13.0  281.5   \n",
      "3    13  318  476  66.8  3883  32   6.7    9   1.9   8.2   8.65  12.2  298.7   \n",
      "4    12  236  327  72.2  3812  40  12.2    4   1.2  11.7  13.55  16.2  317.7   \n",
      "..   ..  ...  ...   ...   ...  ..   ...  ...   ...   ...    ...   ...    ...   \n",
      "770  11  196  356  55.1  2608  21   5.9   16   4.5   7.3   6.48  13.3  237.1   \n",
      "771  11  213  388  54.9  2563  12   3.1   14   3.6   6.6   5.60  12.0  233.0   \n",
      "772  11  171  280  61.1  2547  15   5.4   11   3.9   9.1   8.40  14.9  231.5   \n",
      "773  11  179  373  48.0  2490  17   4.6   26   7.0   6.7   4.45  13.9  226.4   \n",
      "774  11  177  304  58.2  2490  17   5.6    8   2.6   8.2   8.13  14.1  226.4   \n",
      "\n",
      "      Rate  Year  \n",
      "0    157.1  2023  \n",
      "1    188.3  2023  \n",
      "2    167.9  2023  \n",
      "3    153.7  2023  \n",
      "4    208.0  2023  \n",
      "..     ...   ...  \n",
      "770  127.1  1993  \n",
      "771  113.4  1993  \n",
      "772  147.3  1993  \n",
      "773  105.2  1993  \n",
      "774  140.2  1993  \n",
      "\n",
      "[625 rows x 15 columns] 0       1\n",
      "1       2\n",
      "2       3\n",
      "3       4\n",
      "4       5\n",
      "       ..\n",
      "770    21\n",
      "771    22\n",
      "772    23\n",
      "773    24\n",
      "774    25\n",
      "Name: Rk, Length: 625, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b054f9ce766325e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:09.064065Z",
     "start_time": "2024-12-16T15:44:09.054028Z"
    }
   },
   "outputs": [],
   "source": [
    "#convert to numpy\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bd4d364de667d8",
   "metadata": {},
   "source": [
    "#### Build and Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a2f625e3bb31db7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:09.157529Z",
     "start_time": "2024-12-16T15:44:09.113470Z"
    }
   },
   "outputs": [],
   "source": [
    "input_weights = tf.constant([1.0, 1.0, 1.0, 1.0, 1.0, 2.0,1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e3879dc2a8132fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:12.397409Z",
     "start_time": "2024-12-16T15:44:09.206674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0213 - loss: 50956.2500 - val_accuracy: 0.0000e+00 - val_loss: 7001.5723\n",
      "Epoch 2/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0151 - loss: 4182.3901 - val_accuracy: 0.0400 - val_loss: 259.2960\n",
      "Epoch 3/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0246 - loss: 515.2787 - val_accuracy: 0.0400 - val_loss: 178.4823\n",
      "Epoch 4/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0361 - loss: 194.6718 - val_accuracy: 0.0400 - val_loss: 130.9149\n",
      "Epoch 5/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0304 - loss: 127.8977 - val_accuracy: 0.0400 - val_loss: 112.0829\n",
      "Epoch 6/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0325 - loss: 105.2941 - val_accuracy: 0.0400 - val_loss: 84.8033\n",
      "Epoch 7/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0438 - loss: 84.4752 - val_accuracy: 0.0400 - val_loss: 76.7350\n",
      "Epoch 8/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0432 - loss: 70.5626 - val_accuracy: 0.0400 - val_loss: 69.1161\n",
      "Epoch 9/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0257 - loss: 61.1867 - val_accuracy: 0.0400 - val_loss: 61.0921\n",
      "Epoch 10/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0199 - loss: 55.2287 - val_accuracy: 0.0400 - val_loss: 62.0628\n",
      "Epoch 11/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0186 - loss: 54.7112 - val_accuracy: 0.0400 - val_loss: 63.5175\n",
      "Epoch 12/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0185 - loss: 51.8022 - val_accuracy: 0.0400 - val_loss: 58.4008\n",
      "Epoch 13/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0146 - loss: 47.7882 - val_accuracy: 0.0400 - val_loss: 63.0243\n",
      "Epoch 14/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0188 - loss: 47.5290 - val_accuracy: 0.0400 - val_loss: 60.6053\n",
      "Epoch 15/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0209 - loss: 47.7317 - val_accuracy: 0.0400 - val_loss: 57.6288\n",
      "Epoch 16/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0236 - loss: 44.4134 - val_accuracy: 0.0400 - val_loss: 56.2530\n",
      "Epoch 17/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0189 - loss: 43.8057 - val_accuracy: 0.0400 - val_loss: 56.9898\n",
      "Epoch 18/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0209 - loss: 44.6990 - val_accuracy: 0.0333 - val_loss: 50.3355\n",
      "Epoch 19/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0186 - loss: 38.4245 - val_accuracy: 0.0400 - val_loss: 54.1754\n",
      "Epoch 20/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0232 - loss: 39.2728 - val_accuracy: 0.0333 - val_loss: 49.8741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25f29df5d90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "\n",
    "    # tf.keras.WeightedInputLayer(weights=input_weights, input_shape=(15,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer='Adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=20, batch_size=32, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe2d24e59f41dd2",
   "metadata": {},
   "source": [
    "#### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bd5ce146b4f8cf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:12.845942Z",
     "start_time": "2024-12-16T15:44:12.696313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f0554c83a8c01a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:13.063232Z",
     "start_time": "2024-12-16T15:44:13.034927Z"
    }
   },
   "outputs": [],
   "source": [
    "new = pd.DataFrame()\n",
    "\n",
    "new.reset_index(drop=True, inplace=True)\n",
    "X_test_year.reset_index(drop=True, inplace=True)\n",
    "X_test_name.reset_index(drop=True, inplace=True)\n",
    "\n",
    "asa = pd.DataFrame(predictions)\n",
    "\n",
    "new['Prediction'] = asa\n",
    "new['Name'] = X_test_name\n",
    "new['Year'] = X_test_year\n",
    "\n",
    "grouped = new.groupby('Year')\n",
    "years = []\n",
    "\n",
    "for year, group in grouped:\n",
    "    globals()[f\"df_{year}\"] = group\n",
    "    years.append(f\"df_{year}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "706d4efa1291bd77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:13.543920Z",
     "start_time": "2024-12-16T15:44:13.141850Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in years:\n",
    "    globals()[f\"{i}\"] = globals()[f\"{i}\"].sort_values(by='Prediction', ascending=True).head(3)\n",
    "\n",
    "top = Test\n",
    "top = top.iloc[0:0]\n",
    "top.to_csv(\"Top_QB.csv\", index=False)\n",
    "\n",
    "for i in years:\n",
    "    for name in globals()[f\"{i}\"]['Name']:\n",
    "        # print(name)\n",
    "        r = Test[Test.apply(lambda row: row.astype(str).str.contains(name).any(), axis=1)] \n",
    "        r.reset_index(drop=True, inplace=True)        \n",
    "        r.to_csv(\"Top_QB.csv\", mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568cd213dc49a00d",
   "metadata": {},
   "source": [
    "#### Output top 3 QB for each year tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac424bfd062141",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:13.606785Z",
     "start_time": "2024-12-16T15:44:13.594240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rk            Player              Team      Conf   G  Cmp  Att  Cmp%  \\\n",
      "0    2    Cody Ledbetter  New Mexico State  Big West  11  259  453  57.2   \n",
      "1   14   Marcus Crandell     East Carolina       Ind  11  235  447  52.6   \n",
      "2    6     Charlie Batch  Eastern Michigan       MAC  11  244  421  58.0   \n",
      "3    2    Jared Lorenzen          Kentucky       SEC  11  321  559  57.4   \n",
      "4    3   Kliff Kingsbury        Texas Tech    Big 12  12  362  585  61.9   \n",
      "5    1      Chris Weinke     Florida State       ACC  12  266  431  61.7   \n",
      "6    8       Luke Getsy*             Akron       MAC  13  278  525  53.0   \n",
      "7    2      Cody Hodges*        Texas Tech    Big 12  12  353  531  66.5   \n",
      "8    1      Colt Brennan            Hawaii       WAC  12  350  515  68.0   \n",
      "9    2     Landry Jones*          Oklahoma    Big 12  14  405  617  65.6   \n",
      "10   1     Bryant Moniz*            Hawaii       WAC  14  361  555  65.0   \n",
      "11   4  Dominique Davis*     East Carolina      CUSA  13  393  609  64.5   \n",
      "12   2     Matt Johnson*     Bowling Green       MAC  14  383  569  67.3   \n",
      "13   5        Luke Falk*  Washington State    Pac-12  12  448  645  69.5   \n",
      "14   4  Patrick Mahomes*        Texas Tech    Big 12  13  364  573  63.5   \n",
      "15   2       Kyle Trask*           Florida       SEC  12  301  437  68.9   \n",
      "16   5   Dillon Gabriel*               UCF  American  10  248  413  60.0   \n",
      "17   6      Brady White*           Memphis  American  11  254  420  60.5   \n",
      "\n",
      "     Yds  TD  TD%  Int  Int%  Y/A   AY/A   Y/C    Y/G   Rate  Awards  Year  \n",
      "0   3501  30  6.6   20   4.4  7.7   7.07  13.5  318.3  135.1     NaN  1995  \n",
      "1   2751  18  4.0   12   2.7  6.2   5.75  11.7  250.1  112.2     NaN  1995  \n",
      "2   3177  21  5.0   17   4.0  7.5   6.73  13.0  288.8  129.7     NaN  1995  \n",
      "3   3687  19  3.4   21   3.8  6.6   5.58  11.5  335.2  116.5     NaN  2000  \n",
      "4   3418  21  3.6   17   2.9  5.8   5.25   9.4  284.8  117.0     NaN  2000  \n",
      "5   4167  33  7.7   11   2.6  9.7  10.05  15.7  347.3  163.1     1.0  2000  \n",
      "6   3455  23  4.4   12   2.3  6.6   6.43  12.4  265.8  118.1     NaN  2005  \n",
      "7   4197  31  5.8   12   2.3  7.9   8.05  11.9  349.8  147.6     NaN  2005  \n",
      "8   4301  35  6.8   13   2.5  8.4   8.57  12.3  358.4  155.5     NaN  2005  \n",
      "9   4718  38  6.2   12   1.9  7.6   8.00  11.6  337.0  146.3     NaN  2010  \n",
      "10  5040  39  7.0   15   2.7  9.1   9.27  14.0  360.0  159.1     NaN  2010  \n",
      "11  3967  37  6.1   16   2.6  6.5   6.55  10.1  305.2  134.0     NaN  2010  \n",
      "12  4946  46  8.1    8   1.4  8.7   9.68  12.9  353.3  164.2     NaN  2015  \n",
      "13  4566  38  5.9    8   1.2  7.1   7.70  10.2  380.5  145.9     NaN  2015  \n",
      "14  4653  36  6.3   15   2.6  8.1   8.20  12.8  357.9  147.2     NaN  2015  \n",
      "15  4283  43  9.8    8   1.8  9.8  10.95  14.2  356.9  180.0     4.0  2020  \n",
      "16  3570  32  7.7    4   1.0  8.6   9.76  14.4  357.0  156.3     NaN  2020  \n",
      "17  3380  31  7.4   10   2.4  8.0   8.45  13.3  307.3  147.7     NaN  2020  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Top_QB.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7c041104906f2f",
   "metadata": {},
   "source": [
    "## RB Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653a24fed80cb7e1",
   "metadata": {},
   "source": [
    "#where the csv files are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1a5d6c0b794bfb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:13.669194Z",
     "start_time": "2024-12-16T15:44:13.654598Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_path = 'RB_DATA'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169ca7dc751742d8",
   "metadata": {},
   "source": [
    "#all csv files for RBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd66790c0fbf97c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:13.746751Z",
     "start_time": "2024-12-16T15:44:13.732887Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = ['RB_DATA_1993.csv', 'RB_DATA_1994.csv', 'RB_DATA_1995.csv', 'RB_DATA_1996.csv', 'RB_DATA_1997.csv', 'RB_DATA_1998.csv', 'RB_DATA_1999.csv', 'RB_DATA_2000.csv', 'RB_DATA_2002.csv', 'RB_DATA_2003.csv', 'RB_DATA_2004.csv', 'RB_DATA_2005.csv', 'RB_DATA_2006.csv', 'RB_DATA_2007.csv', 'RB_DATA_2008.csv', 'RB_DATA_2009.csv','RB_DATA_2010.csv', 'RB_DATA_2011.csv', 'RB_DATA_2012.csv', 'RB_DATA_2013.csv', 'RB_DATA_2014.csv', 'RB_DATA_2015.csv','RB_DATA_2016.csv', 'RB_DATA_2017.csv', 'RB_DATA_2018.csv', 'RB_DATA_2019.csv', 'RB_DATA_2020.csv', 'RB_DATA_2021.csv', 'RB_DATA_2022.csv', 'RB_DATA_2023.csv' ]  # List to store datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9458140b4b0f2e8a",
   "metadata": {},
   "source": [
    "#list to store player names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6608723c90a7a30b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:13.809397Z",
     "start_time": "2024-12-16T15:44:13.795486Z"
    }
   },
   "outputs": [],
   "source": [
    "player_names_all = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aaebb794e47804",
   "metadata": {},
   "source": [
    "#Lists to store training and testing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "476c4ef9aa7b4e70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:13.871659Z",
     "start_time": "2024-12-16T15:44:13.858476Z"
    }
   },
   "outputs": [],
   "source": [
    "train_results = []\n",
    "test_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f600fc249f3b86",
   "metadata": {},
   "source": [
    "#Create an empty set to store all unique teams and conferences across datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e647de9ff8986d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bda48ab58469d49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:13.933341Z",
     "start_time": "2024-12-16T15:44:13.919649Z"
    }
   },
   "outputs": [],
   "source": [
    "all_teams = set()\n",
    "all_confs = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb41826726521a2",
   "metadata": {},
   "source": [
    "#collecting a full set of unique teams and conferences to use them for one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cd2262e5be4e34e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:14.041474Z",
     "start_time": "2024-12-16T15:44:13.979844Z"
    }
   },
   "outputs": [],
   "source": [
    "# First pass through datasets to collect all unique teams and conferences\n",
    "for dataset in datasets:\n",
    "    file_path = os.path.join(folder_path, dataset)\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Collect all unique teams and conferences\n",
    "    all_teams.update(df['Team'].unique())\n",
    "    all_confs.update(df['Conf'].unique())\n",
    "\n",
    "all_teams = sorted(list(all_teams))\n",
    "all_confs = sorted(list(all_confs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb9382f4deffd59",
   "metadata": {},
   "source": [
    "#Loop through datasets to process them, lots of code in the loop so it is commented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69f33a070d9a322f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:27.035598Z",
     "start_time": "2024-12-16T15:44:14.089192Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fwdav\\PycharmProjects\\ece5831-2024-assignments\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Predicted probabilities for year 1995:\n",
      "[[0.30075973]\n",
      " [0.30075973]\n",
      " [0.30075973]\n",
      " [0.30075973]\n",
      " [0.30075973]\n",
      " [0.30075973]\n",
      " [0.30075973]\n",
      " [0.30075973]\n",
      " [0.30075973]\n",
      " [0.30075973]]\n",
      "Data for year 1995:\n",
      "                  Player  Actual Heisman  Predicted Probability\n",
      "0             Troy Davis               0                0.30076\n",
      "1            Wasean Tait               0                0.30076\n",
      "2           George Jones               0                0.30076\n",
      "3           Eddie George               1                0.30076\n",
      "4  Tshimanga Biakabutuka               0                0.30076\n",
      "Actual Heisman Winner for 1995: Eddie George\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fwdav\\PycharmProjects\\ece5831-2024-assignments\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Predicted probabilities for year 2000:\n",
      "[[0.05083998]\n",
      " [0.05083998]\n",
      " [0.05083998]\n",
      " [0.05083998]\n",
      " [0.05083998]\n",
      " [0.05083998]\n",
      " [0.05083998]\n",
      " [0.05083998]\n",
      " [0.05083998]\n",
      " [0.05083998]]\n",
      "Data for year 2000:\n",
      "                Player  Actual Heisman  Predicted Probability\n",
      "0  LaDainian Tomlinson               1                0.05084\n",
      "1      Damien Anderson               0                0.05084\n",
      "2      Michael Bennett               0                0.05084\n",
      "3      Deonce Whitaker               0                0.05084\n",
      "4       Robert Sanford               0                0.05084\n",
      "Actual Heisman Winner for 2000: LaDainian Tomlinson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fwdav\\PycharmProjects\\ece5831-2024-assignments\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000025F2E943EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Predicted probabilities for year 2005:\n",
      "[[0.04898714]\n",
      " [0.04898714]\n",
      " [0.04898714]\n",
      " [0.04898714]\n",
      " [0.04898714]\n",
      " [0.04898714]\n",
      " [0.04898714]\n",
      " [0.04898714]\n",
      " [0.04898714]\n",
      " [0.04898714]]\n",
      "Data for year 2005:\n",
      "               Player  Actual Heisman  Predicted Probability\n",
      "0  DeAngelo Williams*               0               0.048987\n",
      "1     Jerome Harrison               0               0.048987\n",
      "2        Reggie Bush*               1               0.048987\n",
      "3      Brian Calhoun*               0               0.048987\n",
      "4       Garrett Wolfe               0               0.048987\n",
      "Actual Heisman Winner for 2005: Reggie Bush*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fwdav\\PycharmProjects\\ece5831-2024-assignments\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000025F2C786670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Predicted probabilities for year 2010:\n",
      "[[0.05147699]\n",
      " [0.05147699]\n",
      " [0.05147699]\n",
      " [0.05147699]\n",
      " [0.05147699]\n",
      " [0.05147699]\n",
      " [0.05147699]\n",
      " [0.05147699]\n",
      " [0.05147699]\n",
      " [0.05147699]]\n",
      "Data for year 2010:\n",
      "             Player  Actual Heisman  Predicted Probability\n",
      "0  LaMichael James*               1               0.051477\n",
      "1  Denard Robinson*               0               0.051477\n",
      "2   Mikel Leshoure*               0               0.051477\n",
      "3    Jordan Todman*               0               0.051477\n",
      "4      Bobby Rainey               0               0.051477\n",
      "Actual Heisman Winner for 2010: LaMichael James*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fwdav\\PycharmProjects\\ece5831-2024-assignments\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Predicted probabilities for year 2015:\n",
      "[[0.0506715]\n",
      " [0.0506715]\n",
      " [0.0506715]\n",
      " [0.0506715]\n",
      " [0.0506715]\n",
      " [0.0506715]\n",
      " [0.0506715]\n",
      " [0.0506715]\n",
      " [0.0506715]\n",
      " [0.0506715]]\n",
      "Data for year 2015:\n",
      "                 Player  Actual Heisman  Predicted Probability\n",
      "0        Derrick Henry*               1               0.050672\n",
      "1  Christian McCaffrey*               0               0.050672\n",
      "2    Leonard Fournette*               0               0.050672\n",
      "3        Royce Freeman*               0               0.050672\n",
      "4      Ezekiel Elliott*               0               0.050672\n",
      "Actual Heisman Winner for 2015: Derrick Henry*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fwdav\\PycharmProjects\\ece5831-2024-assignments\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Predicted probabilities for year 2020:\n",
      "[[0.04983077]\n",
      " [0.04983077]\n",
      " [0.04983077]\n",
      " [0.04983077]\n",
      " [0.04983077]\n",
      " [0.04983077]\n",
      " [0.04983077]\n",
      " [0.04983077]\n",
      " [0.04983077]\n",
      " [0.04983077]]\n",
      "Data for year 2020:\n",
      "               Player  Actual Heisman  Predicted Probability\n",
      "0        Breece Hall*               0               0.049831\n",
      "1  Sincere McCormick*               0               0.049831\n",
      "2       Najee Harris*               1               0.049831\n",
      "3     Michael Carter*               0               0.049831\n",
      "4      Khalil Herbert               0               0.049831\n",
      "Actual Heisman Winner for 2020: Najee Harris*\n",
      "   Year                                  Predicted Winners  \\\n",
      "0  1995              Troy Davis, Wasean Tait, George Jones   \n",
      "1  2000  Sultan McCullough, Michael Wallace, LaDainian ...   \n",
      "2  2005  DeAngelo Williams*, Jerome Harrison, Reggie Bush*   \n",
      "3  2010  LaMichael James*, Denard Robinson*, Mikel Lesh...   \n",
      "4  2015  Derrick Henry*, Christian McCaffrey*, Leonard ...   \n",
      "5  2020     Jarek Broussard*, Spencer Brown, Brenden Knox*   \n",
      "\n",
      "         Actual Winner Match  \n",
      "0         Eddie George    No  \n",
      "1  LaDainian Tomlinson   Yes  \n",
      "2         Reggie Bush*   Yes  \n",
      "3     LaMichael James*   Yes  \n",
      "4       Derrick Henry*   Yes  \n",
      "5        Najee Harris*    No  \n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    # Extract the year from the dataset name\n",
    "    year = dataset.split('_')[-1].split('.')[0]\n",
    "    file_path = os.path.join(folder_path, dataset)\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Ensure 'Awards' column exists and clean it\n",
    "    if 'Awards' not in df.columns:\n",
    "        print(f\"Warning: 'Awards' column not found in {dataset}. Skipping this dataset.\")\n",
    "        continue\n",
    "    \n",
    "    df['Awards'] = df['Awards'].fillna(0).astype(int)  # Clean 'Awards' column\n",
    "\n",
    "    # Check for Heisman winner (only one should be present)\n",
    "    heisman_winners = df[df['Awards'] == 1]\n",
    "    if len(heisman_winners) != 1:\n",
    "        print(f\"Warning: More than one or no Heisman winner found in {year} dataset!\")\n",
    "        continue  # Skip this dataset if there's no valid Heisman winner\n",
    "    \n",
    "    # Track player names\n",
    "    player_names_all.append(df['Player'].values)\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = df.drop(['Awards', 'Player'], axis=1).select_dtypes(include=['number'])\n",
    "    y = df['Awards']\n",
    "\n",
    "    # One-Hot Encoding for 'Team' and 'Conf', ensuring consistency across datasets\n",
    "    X_encoded = pd.concat([\n",
    "        X,\n",
    "        pd.get_dummies(df['Team'], prefix='Team').reindex(columns=all_teams, fill_value=0),\n",
    "        pd.get_dummies(df['Conf'], prefix='Conf').reindex(columns=all_confs, fill_value=0)\n",
    "    ], axis=1)\n",
    "\n",
    "    # Reset index for consistency\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Check if this year should be used for testing or training\n",
    "    if year[-1] in ['0', '5']:  # Testing set for years ending in '0' or '5'\n",
    "        # Split data into test set\n",
    "        X_test = X_encoded\n",
    "        y_test = y\n",
    "\n",
    "        # Scale the data for testing\n",
    "        scaler = StandardScaler()\n",
    "        X_test_scaled = scaler.fit_transform(X_test)\n",
    "        \n",
    "        # Build the model\n",
    "        model = tf.keras.Sequential([ \n",
    "            tf.keras.layers.Dense(128, activation='relu', input_shape=(X_test_scaled.shape[1],)),  # Increased complexity\n",
    "            tf.keras.layers.Dropout(0.2),  # Add dropout to prevent overfitting\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),  # Add dropout here as well\n",
    "            tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid') \n",
    "        ])\n",
    "\n",
    "        # Compile the model with adjusted learning rate and class weight\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  # Adjust learning rate\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model on the training set from previous years\n",
    "        if len(train_results) > 0:\n",
    "            X_train_scaled = np.concatenate([result['X_train_scaled'] for result in train_results], axis=0)\n",
    "            y_train = np.concatenate([result['y_train'] for result in train_results], axis=0)\n",
    "            \n",
    "            model.fit(X_train_scaled, y_train, epochs=30, batch_size=32, verbose=0)\n",
    "\n",
    "            # Predict on the test set and get probabilities\n",
    "            y_pred_prob = model.predict(X_test_scaled)\n",
    "\n",
    "            # Debugging: Print out the predicted probabilities to check for improvement\n",
    "            print(f\"Predicted probabilities for year {year}:\")\n",
    "            print(y_pred_prob[:10])  # Display first 10 predictions\n",
    "                    \n",
    "        # Retrieve player names for the test set\n",
    "        test_player_names = df.loc[X_test.index, 'Player'].values\n",
    "\n",
    "        # Prepare the test data for comparison\n",
    "        test_data = X_test.copy()\n",
    "        test_data['Actual Heisman'] = y_test.values\n",
    "        test_data['Player'] = test_player_names\n",
    "        test_data['Predicted Probability'] = y_pred_prob\n",
    "\n",
    "        print(f\"Data for year {year}:\")\n",
    "        print(test_data[['Player', 'Actual Heisman', 'Predicted Probability']].head()) \n",
    "\n",
    "        # Sort by predicted probability to get the top 3 predicted winners\n",
    "        top_3_predicted = test_data.nlargest(3, 'Predicted Probability')[['Player', 'Predicted Probability']]\n",
    "\n",
    "        # Get player statistics for the top 3 by looking them up in the original dataset\n",
    "        top_3_stats = df[df['Player'].isin(top_3_predicted['Player'].values)][[\n",
    "            'Player', 'Team', 'Conf', 'G', 'Att', 'Yds', 'Y/A', 'TD', 'Y/G', 'Rec', 'Yds.1', \n",
    "            'Y/R', 'TD.1', 'Y/G.1', 'Plays', 'Yds.2', 'Avg', 'TD.2'\n",
    "        ]]\n",
    "\n",
    "        # Add a custom identifier with format 'player-name-id'\n",
    "        top_3_stats['-9999'] = top_3_stats['Player'].str.lower().str.replace(' ', '-')\n",
    "        \n",
    "        # Save the top 3 players and their stats for this year in the same format as the original CSV\n",
    "        output_file_path = os.path.join('RB_DATA', f'top_3_players_{year}.csv')\n",
    "        top_3_stats.to_csv(output_file_path, index=False)\n",
    "\n",
    "        # Check if there is at least one actual Heisman winner\n",
    "        actual_winner = test_data[test_data['Actual Heisman'] == 1]\n",
    "        \n",
    "        if actual_winner.empty:\n",
    "            print(f\"Warning: No actual Heisman winner found for {year}. Skipping this dataset.\")\n",
    "            continue  # Skip this year if there's no actual winner\n",
    "\n",
    "        # If there's an actual winner, get the name\n",
    "        actual_winner_name = actual_winner['Player'].values[0]\n",
    "        print(f\"Actual Heisman Winner for {year}: {actual_winner_name}\")  \n",
    "\n",
    "        # Check if one of the predicted winners matches the actual winner\n",
    "        predicted_winners = top_3_predicted['Player'].values\n",
    "        match = 'Yes' if actual_winner_name in predicted_winners else 'No'\n",
    "\n",
    "        # Store the test results for this year\n",
    "        test_results.append({\n",
    "            'Year': year,\n",
    "            'Predicted Winners': ', '.join(predicted_winners),\n",
    "            'Actual Winner': actual_winner_name,\n",
    "            'Match': match\n",
    "        })\n",
    "\n",
    "    else:  # Training set for all other years\n",
    "        # Use the entire dataset as the training set\n",
    "        X_train = X_encoded\n",
    "        y_train = y\n",
    "        \n",
    "        # Scale the data for training\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        # Store training results for later use\n",
    "        train_results.append({\n",
    "            'X_train_scaled': X_train_scaled,\n",
    "            'y_train': y_train\n",
    "        })\n",
    "        \n",
    "test_results_df = pd.DataFrame(test_results)\n",
    "\n",
    "#printing top 3 from each test year\n",
    "print(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c41bc416474213",
   "metadata": {},
   "source": [
    "## QB vs RB Model\n",
    "#### Import and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91c1a824b958de33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:27.159374Z",
     "start_time": "2024-12-16T15:44:27.130935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year             QB_1 QB_Conf_1  QB_Rank_1  QB_Games_1  Pass_Cmp_1  \\\n",
      "0  2023   Jayden Daniels       SEC          5          12         236   \n",
      "1  2022   Caleb Williams    Pac-12          3          14         333   \n",
      "2  2021      Bryce Young       SEC          2          15         366   \n",
      "3  2020  Trevor Lawrence       ACC          8          10         231   \n",
      "4  2019       Joe Burrow       SEC          1          15         402   \n",
      "\n",
      "   Pass_Att_1  Cmp%_1  Pass_Yds_1  Pass_TD_1  ...  Int_per_Game_1  \\\n",
      "0         327    72.2        3812         40  ...        0.333333   \n",
      "1         500    66.6        4537         42  ...        0.357143   \n",
      "2         547    66.9        4872         47  ...        0.466667   \n",
      "3         334    69.2        3153         24  ...        0.500000   \n",
      "4         527    76.3        5671         60  ...        0.400000   \n",
      "\n",
      "   Rush_Att_per_Game_1  Rush_Yds_per_Game_1  Rush_TD_per_Game_1  \\\n",
      "0            20.357143           123.714286                 1.5   \n",
      "1            20.583333           121.916667                 1.5   \n",
      "2            21.916667           136.333333                 1.5   \n",
      "3            19.307692           112.769231                 2.0   \n",
      "4            22.857143           143.071429                 1.5   \n",
      "\n",
      "   Rec_per_Game_1  Rcv_Yds_per_Game_1  Rcv_TD_per_Game_1  \\\n",
      "0        2.785714           23.571429           0.071429   \n",
      "1        0.916667            6.666667           0.083333   \n",
      "2        1.083333            7.416667           0.083333   \n",
      "3        3.307692           32.692308           0.307692   \n",
      "4        1.857143           18.000000           0.357143   \n",
      "\n",
      "   ScrmgPlays_per_Game_1 Scrmg_Yds_per_Game_1 Scrmg_TD_per_Game_1  \n",
      "0              23.142857           147.285714            1.571429  \n",
      "1              21.500000           128.583333            1.583333  \n",
      "2              23.000000           143.750000            1.583333  \n",
      "3              22.615385           145.461538            2.307692  \n",
      "4              24.714286           161.071429            1.857143  \n",
      "\n",
      "[5 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "input_df = pd.read_csv('Heisman_Winner_QB_vs_RB_Singles.csv')\n",
    "#print(input_data_cv.head())\n",
    "\n",
    "#Standardize stats by # of games played\n",
    "input_df['Pass_Cmp_per_Game_1'] = input_df['Pass_Cmp_1']/input_df['QB_Games_1']\n",
    "input_df['Pass_Att_per_Game_1'] = input_df['Pass_Att_1']/input_df['QB_Games_1']\n",
    "input_df['Pass_TD_per_Game_1'] = input_df['Pass_TD_1']/input_df['QB_Games_1']\n",
    "input_df['Int_per_Game_1'] = input_df['Int_1']/input_df['QB_Games_1']\n",
    "\n",
    "input_df['Rush_Att_per_Game_1'] = input_df['Rush_Att_1']/input_df['RB_Games_1']\n",
    "input_df['Rush_Yds_per_Game_1'] = input_df['Rush_Yds_1']/input_df['RB_Games_1']\n",
    "input_df['Rush_TD_per_Game_1'] = input_df['Rush_TD_1']/input_df['RB_Games_1']\n",
    "input_df['Rec_per_Game_1'] = input_df['Rec_1']/input_df['RB_Games_1']\n",
    "input_df['Rcv_Yds_per_Game_1'] = input_df['Rcv_Yds_1']/input_df['RB_Games_1']\n",
    "input_df['Rcv_TD_per_Game_1'] = input_df['Rcv_TD_1']/input_df['RB_Games_1']\n",
    "input_df['ScrmgPlays_per_Game_1'] = input_df['ScrmgPlays_1']/input_df['RB_Games_1']\n",
    "input_df['Scrmg_Yds_per_Game_1'] = input_df['Scrmg_Yds_1']/input_df['RB_Games_1']\n",
    "input_df['Scrmg_TD_per_Game_1'] = input_df['Scrmg_TD_1']/input_df['RB_Games_1']\n",
    "\n",
    "\n",
    "print(input_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51047e60d8efd57",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f6dcde9ed92d99b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:27.284225Z",
     "start_time": "2024-12-16T15:44:27.256096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.0\n",
      "1     0.0\n",
      "2     0.0\n",
      "3     0.0\n",
      "4     0.0\n",
      "5     0.0\n",
      "6     0.0\n",
      "7     0.0\n",
      "8     1.0\n",
      "9     0.0\n",
      "10    0.0\n",
      "11    0.0\n",
      "12    0.0\n",
      "13    0.0\n",
      "14    1.0\n",
      "15    0.0\n",
      "16    0.0\n",
      "17    0.0\n",
      "18    1.0\n",
      "19    0.0\n",
      "20    0.0\n",
      "21    0.0\n",
      "22    0.0\n",
      "23    1.0\n",
      "24    1.0\n",
      "25    0.0\n",
      "26    0.0\n",
      "27    1.0\n",
      "28    1.0\n",
      "29    0.0\n",
      "Name: Winner_Coded, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Create new column to indicate which player won the Heisman\n",
    "input_df['Winner_Coded'] = '999'\n",
    "for row in range(input_df.shape[0]):\n",
    "    if input_df['Winner'][row] == input_df['QB_1'][row]:\n",
    "        input_df.loc[row, 'Winner_Coded'] = 0.0\n",
    "    if input_df['Winner'][row] == input_df['RB_1'][row]:\n",
    "        input_df.loc[row, 'Winner_Coded'] = 1.0\n",
    "print(input_df['Winner_Coded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70065b5c227c2b3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22e72a970cba2472",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:27.440001Z",
     "start_time": "2024-12-16T15:44:27.397461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SEC' 'Pac-12' 'ACC' 'Big 12' 'Big Ten']\n",
      "['Big 12' 'Big Ten' 'SEC' 'ACC' 'Pac-12' 'WAC']\n",
      "['SEC' 'Pac-12' 'ACC' 'Big 12' 'Big Ten']\n",
      "['Big 12' 'Big Ten' 'SEC' 'ACC' 'Pac-12' 'WAC']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>QB_1</th>\n",
       "      <th>QB_Conf_1</th>\n",
       "      <th>QB_Rank_1</th>\n",
       "      <th>QB_Games_1</th>\n",
       "      <th>Pass_Cmp_1</th>\n",
       "      <th>Pass_Att_1</th>\n",
       "      <th>Cmp%_1</th>\n",
       "      <th>Pass_Yds_1</th>\n",
       "      <th>Pass_TD_1</th>\n",
       "      <th>...</th>\n",
       "      <th>ScrmgPlays_per_Game_1</th>\n",
       "      <th>Scrmg_Yds_per_Game_1</th>\n",
       "      <th>Scrmg_TD_per_Game_1</th>\n",
       "      <th>Winner_Coded</th>\n",
       "      <th>RB1__ACC</th>\n",
       "      <th>RB1__Big 12</th>\n",
       "      <th>RB1__Big Ten</th>\n",
       "      <th>RB1__Pac-12</th>\n",
       "      <th>RB1__SEC</th>\n",
       "      <th>RB1__WAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>Jayden Daniels</td>\n",
       "      <td>SEC</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>236</td>\n",
       "      <td>327</td>\n",
       "      <td>72.2</td>\n",
       "      <td>3812</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>23.142857</td>\n",
       "      <td>147.285714</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>Caleb Williams</td>\n",
       "      <td>Pac-12</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>333</td>\n",
       "      <td>500</td>\n",
       "      <td>66.6</td>\n",
       "      <td>4537</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>128.583333</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>Bryce Young</td>\n",
       "      <td>SEC</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>366</td>\n",
       "      <td>547</td>\n",
       "      <td>66.9</td>\n",
       "      <td>4872</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>143.750000</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>Trevor Lawrence</td>\n",
       "      <td>ACC</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>231</td>\n",
       "      <td>334</td>\n",
       "      <td>69.2</td>\n",
       "      <td>3153</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>22.615385</td>\n",
       "      <td>145.461538</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>Joe Burrow</td>\n",
       "      <td>SEC</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>402</td>\n",
       "      <td>527</td>\n",
       "      <td>76.3</td>\n",
       "      <td>5671</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>24.714286</td>\n",
       "      <td>161.071429</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>Kyler Murray</td>\n",
       "      <td>Big 12</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>260</td>\n",
       "      <td>377</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4361</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>115.733333</td>\n",
       "      <td>1.733333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017</td>\n",
       "      <td>Baker Mayfield</td>\n",
       "      <td>Big 12</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>285</td>\n",
       "      <td>404</td>\n",
       "      <td>70.5</td>\n",
       "      <td>4627</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>20.692308</td>\n",
       "      <td>165.461538</td>\n",
       "      <td>1.461538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>Lamar Jackson</td>\n",
       "      <td>ACC</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>230</td>\n",
       "      <td>409</td>\n",
       "      <td>56.2</td>\n",
       "      <td>3543</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>191.181818</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015</td>\n",
       "      <td>Deshaun Watson</td>\n",
       "      <td>ACC</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>333</td>\n",
       "      <td>491</td>\n",
       "      <td>67.8</td>\n",
       "      <td>4104</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>27.066667</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014</td>\n",
       "      <td>Marcus Mariota</td>\n",
       "      <td>Pac-12</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>304</td>\n",
       "      <td>445</td>\n",
       "      <td>68.3</td>\n",
       "      <td>4454</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>25.857143</td>\n",
       "      <td>195.714286</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013</td>\n",
       "      <td>Jameis Winston</td>\n",
       "      <td>ACC</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>257</td>\n",
       "      <td>384</td>\n",
       "      <td>66.9</td>\n",
       "      <td>4057</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>27.307692</td>\n",
       "      <td>167.461538</td>\n",
       "      <td>1.384615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012</td>\n",
       "      <td>Johnny Manziel</td>\n",
       "      <td>SEC</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>295</td>\n",
       "      <td>434</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3706</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>22.923077</td>\n",
       "      <td>155.615385</td>\n",
       "      <td>1.769231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2011</td>\n",
       "      <td>Robert Griffin III</td>\n",
       "      <td>Big 12</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>291</td>\n",
       "      <td>402</td>\n",
       "      <td>72.4</td>\n",
       "      <td>4293</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>19.692308</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>1.692308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2010</td>\n",
       "      <td>Cam Newton</td>\n",
       "      <td>SEC</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>185</td>\n",
       "      <td>280</td>\n",
       "      <td>66.1</td>\n",
       "      <td>2854</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>25.916667</td>\n",
       "      <td>161.583333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2009</td>\n",
       "      <td>Colt McCoy</td>\n",
       "      <td>Big 12</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>332</td>\n",
       "      <td>470</td>\n",
       "      <td>70.6</td>\n",
       "      <td>3521</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>21.642857</td>\n",
       "      <td>142.285714</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2008</td>\n",
       "      <td>Sam Bradford</td>\n",
       "      <td>Big 12</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>328</td>\n",
       "      <td>483</td>\n",
       "      <td>67.9</td>\n",
       "      <td>4720</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>24.230769</td>\n",
       "      <td>146.076923</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2007</td>\n",
       "      <td>Tim Tebow</td>\n",
       "      <td>SEC</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>234</td>\n",
       "      <td>350</td>\n",
       "      <td>66.9</td>\n",
       "      <td>3286</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>26.615385</td>\n",
       "      <td>153.384615</td>\n",
       "      <td>1.307692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2006</td>\n",
       "      <td>Troy Smith</td>\n",
       "      <td>Big Ten</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>203</td>\n",
       "      <td>311</td>\n",
       "      <td>65.3</td>\n",
       "      <td>2542</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>21.071429</td>\n",
       "      <td>128.285714</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2005</td>\n",
       "      <td>Vince Young</td>\n",
       "      <td>Big 12</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>212</td>\n",
       "      <td>325</td>\n",
       "      <td>65.2</td>\n",
       "      <td>3036</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>18.230769</td>\n",
       "      <td>170.615385</td>\n",
       "      <td>1.384615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2004</td>\n",
       "      <td>Matt Leinart</td>\n",
       "      <td>Pac-12</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>269</td>\n",
       "      <td>412</td>\n",
       "      <td>65.3</td>\n",
       "      <td>3322</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>26.461538</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2003</td>\n",
       "      <td>Jason White</td>\n",
       "      <td>Big 12</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>278</td>\n",
       "      <td>451</td>\n",
       "      <td>61.6</td>\n",
       "      <td>3846</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>29.384615</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2002</td>\n",
       "      <td>Carson Palmer</td>\n",
       "      <td>Pac-12</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>309</td>\n",
       "      <td>489</td>\n",
       "      <td>63.2</td>\n",
       "      <td>3942</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>187.384615</td>\n",
       "      <td>1.769231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2000</td>\n",
       "      <td>Chris Weinke</td>\n",
       "      <td>ACC</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>266</td>\n",
       "      <td>431</td>\n",
       "      <td>61.7</td>\n",
       "      <td>4167</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>34.454545</td>\n",
       "      <td>199.818182</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1999</td>\n",
       "      <td>Joe Hamilton</td>\n",
       "      <td>ACC</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>203</td>\n",
       "      <td>305</td>\n",
       "      <td>66.6</td>\n",
       "      <td>3060</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>27.636364</td>\n",
       "      <td>167.545455</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1998</td>\n",
       "      <td>Michael Bishop</td>\n",
       "      <td>Big 12</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>164</td>\n",
       "      <td>295</td>\n",
       "      <td>55.6</td>\n",
       "      <td>2844</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>216.909091</td>\n",
       "      <td>2.545455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1997</td>\n",
       "      <td>Peyton Manning</td>\n",
       "      <td>SEC</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>287</td>\n",
       "      <td>477</td>\n",
       "      <td>60.2</td>\n",
       "      <td>3819</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>143.454545</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1996</td>\n",
       "      <td>Danny Wuerffel</td>\n",
       "      <td>SEC</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>207</td>\n",
       "      <td>360</td>\n",
       "      <td>57.5</td>\n",
       "      <td>3625</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>37.727273</td>\n",
       "      <td>204.454545</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1995</td>\n",
       "      <td>Tommie Frazier</td>\n",
       "      <td>Big Ten</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "      <td>92</td>\n",
       "      <td>163</td>\n",
       "      <td>56.4</td>\n",
       "      <td>1362</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>28.916667</td>\n",
       "      <td>185.416667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1994</td>\n",
       "      <td>Kerry Collins</td>\n",
       "      <td>Big Ten</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>176</td>\n",
       "      <td>264</td>\n",
       "      <td>66.7</td>\n",
       "      <td>2679</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>29.272727</td>\n",
       "      <td>213.545455</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1993</td>\n",
       "      <td>Charlie Ward</td>\n",
       "      <td>ACC</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>264</td>\n",
       "      <td>380</td>\n",
       "      <td>69.5</td>\n",
       "      <td>3032</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>8.583333</td>\n",
       "      <td>106.500000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year                QB_1 QB_Conf_1  QB_Rank_1  QB_Games_1  Pass_Cmp_1  \\\n",
       "0   2023      Jayden Daniels       SEC          5          12         236   \n",
       "1   2022      Caleb Williams    Pac-12          3          14         333   \n",
       "2   2021         Bryce Young       SEC          2          15         366   \n",
       "3   2020     Trevor Lawrence       ACC          8          10         231   \n",
       "4   2019          Joe Burrow       SEC          1          15         402   \n",
       "5   2018        Kyler Murray    Big 12          3          14         260   \n",
       "6   2017      Baker Mayfield    Big 12          2          14         285   \n",
       "7   2016       Lamar Jackson       ACC         16          13         230   \n",
       "8   2015      Deshaun Watson       ACC          9          15         333   \n",
       "9   2014      Marcus Mariota    Pac-12          3          15         304   \n",
       "10  2013      Jameis Winston       ACC          9          14         257   \n",
       "11  2012      Johnny Manziel       SEC         15          13         295   \n",
       "12  2011  Robert Griffin III    Big 12          6          13         291   \n",
       "13  2010          Cam Newton       SEC         36          14         185   \n",
       "14  2009          Colt McCoy    Big 12         11          14         332   \n",
       "15  2008        Sam Bradford    Big 12          3          14         328   \n",
       "16  2007           Tim Tebow       SEC         23          13         234   \n",
       "17  2006          Troy Smith   Big Ten         38          13         203   \n",
       "18  2005         Vince Young    Big 12         18          13         212   \n",
       "19  2004        Matt Leinart    Pac-12          8          13         269   \n",
       "20  2003         Jason White    Big 12          7          14         278   \n",
       "21  2002       Carson Palmer    Pac-12          5          13         309   \n",
       "22  2000        Chris Weinke       ACC          1          12         266   \n",
       "23  1999        Joe Hamilton       ACC         15          11         203   \n",
       "24  1998      Michael Bishop    Big 12         16          12         164   \n",
       "25  1997      Peyton Manning       SEC          3          12         287   \n",
       "26  1996      Danny Wuerffel       SEC          4          12         207   \n",
       "27  1995      Tommie Frazier   Big Ten         80          11          92   \n",
       "28  1994       Kerry Collins   Big Ten         11          11         176   \n",
       "29  1993        Charlie Ward       ACC         14          11         264   \n",
       "\n",
       "    Pass_Att_1  Cmp%_1  Pass_Yds_1  Pass_TD_1  ...  ScrmgPlays_per_Game_1  \\\n",
       "0          327    72.2        3812         40  ...              23.142857   \n",
       "1          500    66.6        4537         42  ...              21.500000   \n",
       "2          547    66.9        4872         47  ...              23.000000   \n",
       "3          334    69.2        3153         24  ...              22.615385   \n",
       "4          527    76.3        5671         60  ...              24.714286   \n",
       "5          377    69.0        4361         42  ...              14.400000   \n",
       "6          404    70.5        4627         43  ...              20.692308   \n",
       "7          409    56.2        3543         30  ...              30.000000   \n",
       "8          491    67.8        4104         35  ...              27.066667   \n",
       "9          445    68.3        4454         42  ...              25.857143   \n",
       "10         384    66.9        4057         40  ...              27.307692   \n",
       "11         434    68.0        3706         26  ...              22.923077   \n",
       "12         402    72.4        4293         37  ...              19.692308   \n",
       "13         280    66.1        2854         30  ...              25.916667   \n",
       "14         470    70.6        3521         27  ...              21.642857   \n",
       "15         483    67.9        4720         50  ...              24.230769   \n",
       "16         350    66.9        3286         32  ...              26.615385   \n",
       "17         311    65.3        2542         30  ...              21.071429   \n",
       "18         325    65.2        3036         26  ...              18.230769   \n",
       "19         412    65.3        3322         33  ...              26.461538   \n",
       "20         451    61.6        3846         40  ...              29.384615   \n",
       "21         489    63.2        3942         33  ...              24.000000   \n",
       "22         431    61.7        4167         33  ...              34.454545   \n",
       "23         305    66.6        3060         29  ...              27.636364   \n",
       "24         295    55.6        2844         23  ...              35.000000   \n",
       "25         477    60.2        3819         36  ...              23.000000   \n",
       "26         360    57.5        3625         39  ...              37.727273   \n",
       "27         163    56.4        1362         17  ...              28.916667   \n",
       "28         264    66.7        2679         21  ...              29.272727   \n",
       "29         380    69.5        3032         27  ...               8.583333   \n",
       "\n",
       "    Scrmg_Yds_per_Game_1  Scrmg_TD_per_Game_1  Winner_Coded  RB1__ACC  \\\n",
       "0             147.285714             1.571429           0.0         0   \n",
       "1             128.583333             1.583333           0.0         0   \n",
       "2             143.750000             1.583333           0.0         0   \n",
       "3             145.461538             2.307692           0.0         0   \n",
       "4             161.071429             1.857143           0.0         0   \n",
       "5             115.733333             1.733333           0.0         1   \n",
       "6             165.461538             1.461538           0.0         0   \n",
       "7             191.181818             1.363636           0.0         0   \n",
       "8             154.000000             1.866667           1.0         0   \n",
       "9             195.714286             2.285714           0.0         0   \n",
       "10            167.461538             1.384615           0.0         1   \n",
       "11            155.615385             1.769231           0.0         0   \n",
       "12            123.000000             1.692308           0.0         0   \n",
       "13            161.583333             2.000000           0.0         0   \n",
       "14            142.285714             1.428571           1.0         0   \n",
       "15            146.076923             1.538462           0.0         0   \n",
       "16            153.384615             1.307692           0.0         0   \n",
       "17            128.285714             1.071429           0.0         0   \n",
       "18            170.615385             1.384615           1.0         0   \n",
       "19            149.000000             1.153846           0.0         0   \n",
       "20            157.000000             1.538462           0.0         0   \n",
       "21            187.384615             1.769231           0.0         0   \n",
       "22            199.818182             2.000000           0.0         0   \n",
       "23            167.545455             1.727273           1.0         0   \n",
       "24            216.909091             2.545455           1.0         0   \n",
       "25            143.454545             1.818182           0.0         0   \n",
       "26            204.454545             1.909091           0.0         0   \n",
       "27            185.416667             2.000000           1.0         0   \n",
       "28            213.545455             2.181818           1.0         0   \n",
       "29            106.500000             0.583333           0.0         0   \n",
       "\n",
       "    RB1__Big 12  RB1__Big Ten  RB1__Pac-12 RB1__SEC RB1__WAC  \n",
       "0             1             0            0        0        0  \n",
       "1             0             1            0        0        0  \n",
       "2             0             1            0        0        0  \n",
       "3             0             0            0        1        0  \n",
       "4             0             1            0        0        0  \n",
       "5             0             0            0        0        0  \n",
       "6             0             0            1        0        0  \n",
       "7             1             0            0        0        0  \n",
       "8             0             0            0        1        0  \n",
       "9             0             1            0        0        0  \n",
       "10            0             0            0        0        0  \n",
       "11            0             0            1        0        0  \n",
       "12            0             0            0        1        0  \n",
       "13            0             0            1        0        0  \n",
       "14            0             0            0        1        0  \n",
       "15            0             1            0        0        0  \n",
       "16            0             0            0        1        0  \n",
       "17            0             0            0        1        0  \n",
       "18            0             0            1        0        0  \n",
       "19            1             0            0        0        0  \n",
       "20            0             1            0        0        0  \n",
       "21            0             1            0        0        0  \n",
       "22            0             0            0        0        1  \n",
       "23            0             1            0        0        0  \n",
       "24            1             0            0        0        0  \n",
       "25            0             1            0        0        0  \n",
       "26            1             0            0        0        0  \n",
       "27            0             1            0        0        0  \n",
       "28            1             0            0        0        0  \n",
       "29            0             0            0        1        0  \n",
       "\n",
       "[30 rows x 55 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Format conference fields \n",
    "print(input_df['QB_Conf_1'].unique())\n",
    "print(input_df['RB_Conf_1'].unique())\n",
    "input_df['QB_Conf_1'] = input_df['QB_Conf_1'].str.strip()\n",
    "input_df['RB_Conf_1'] = input_df['RB_Conf_1'].str.strip()\n",
    "\n",
    "input_df['RB_Conf_1'] = input_df['RB_Conf_1'].replace({'Pac-10':'Pac-12'})\n",
    "print(input_df['QB_Conf_1'].unique())\n",
    "print(input_df['RB_Conf_1'].unique())\n",
    "\n",
    "#Create dummy vars for  conferences\n",
    "pd.concat([input_df, pd.get_dummies(input_df['QB_Conf_1'],prefix='QB1_').astype(int)], axis=1)\n",
    "pd.concat([input_df, pd.get_dummies(input_df['RB_Conf_1'],prefix='RB1_').astype(int)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d82f8a1425bf2424",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:27.595896Z",
     "start_time": "2024-12-16T15:44:27.581742Z"
    }
   },
   "outputs": [],
   "source": [
    "#Drop non-standardized variables\n",
    "vars_final = input_df.drop(columns = ['Pass_Cmp_1','Pass_Att_1','Pass_Yds_1', 'Pass_TD_1', 'Int_1', 'Rush_Att_1',\n",
    "                                      'Rush_Yds_1', 'Rush_TD_1', 'Rec_1','Rcv_Yds_1','Rcv_TD_1','ScrmgPlays_1',\n",
    "                                      'Scrmg_Yds_1','Scrmg_TD_1',\n",
    "                                      'Winner', 'QB_Conf_1', 'RB_Conf_1'])\n",
    "\n",
    "#Drop variables we won't be using to predict\n",
    "vars_final.drop(columns = ['QB_1', 'RB_1'], inplace=True)\n",
    "#vars_final.drop(columns = ['QB_Rank_1', 'QB_Rank_2', 'QB_Rank_3', 'RB_Rank_1', 'RB_Rank_2', 'RB_Rank_3',\n",
    "                           #'QB_Games_1', 'QB_Games_2', 'QB_Games_3', 'RB_Games_1', 'RB_Games_2', 'RB_Games_3'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb585810031dcb52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:27.626969Z",
     "start_time": "2024-12-16T15:44:27.615554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'QB_Rank_1', 'QB_Games_1', 'Cmp%_1', 'Pass_TD%_1', 'Int%_1',\n",
      "       'Y_per_Atmpt_1', 'Adj_Y_per_A_1', 'Y_per_C_1', 'Y_per_G_1',\n",
      "       'Pass_Effncy_Rate_1', 'RB_Rank_1', 'RB_Games_1', 'Rush_Avg_1',\n",
      "       'Rcv_Avg_1', 'Scrmg_Avg_1', 'Pass_Cmp_per_Game_1',\n",
      "       'Pass_Att_per_Game_1', 'Pass_TD_per_Game_1', 'Int_per_Game_1',\n",
      "       'Rush_Att_per_Game_1', 'Rush_Yds_per_Game_1', 'Rush_TD_per_Game_1',\n",
      "       'Rec_per_Game_1', 'Rcv_Yds_per_Game_1', 'Rcv_TD_per_Game_1',\n",
      "       'ScrmgPlays_per_Game_1', 'Scrmg_Yds_per_Game_1', 'Scrmg_TD_per_Game_1',\n",
      "       'Winner_Coded'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(vars_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69186c1b101d452f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:27.704846Z",
     "start_time": "2024-12-16T15:44:27.691549Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create X and y tensors\n",
    "X = vars_final.drop(columns = ['Year','Winner_Coded'])\n",
    "y = vars_final['Winner_Coded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "454f0f6f76bab0a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:27.751144Z",
     "start_time": "2024-12-16T15:44:27.737920Z"
    }
   },
   "outputs": [],
   "source": [
    "#Standardize X\n",
    "train_mean = X.mean(axis=0)\n",
    "X -= train_mean\n",
    "train_std = X.std(axis=0)\n",
    "X /= train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4ab57d6aac1d28f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:27.844048Z",
     "start_time": "2024-12-16T15:44:27.815152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    QB_Rank_1  QB_Games_1    Cmp%_1  Pass_TD%_1    Int%_1  Y_per_Atmpt_1  \\\n",
      "0   -0.475936   -0.732828  1.260621    2.001964 -1.138228       1.956380   \n",
      "1   -0.602853    0.732828  0.142436   -0.253213 -1.414721      -0.284408   \n",
      "2   -0.666311    1.465656  0.202338   -0.134519 -0.999982      -0.456776   \n",
      "3   -0.285562   -2.198484  0.661593   -0.965374 -0.723489      -0.025855   \n",
      "4   -0.729769    1.465656  2.079293    1.527190 -1.276475       1.180723   \n",
      "5   -0.602853    0.732828  0.621658    1.349150 -0.170504       1.870196   \n",
      "6   -0.666311    0.732828  0.921172    1.052416 -0.723489       1.784012   \n",
      "7    0.222104    0.000000 -1.934195   -0.906027  0.244235      -0.629144   \n",
      "8   -0.222104    1.465656  0.382047   -1.024721  0.797221      -0.887697   \n",
      "9   -0.602853    1.465656  0.481885    0.340255 -1.552968       0.491250   \n",
      "10  -0.222104    0.732828  0.202338    0.933723  0.797221       1.008355   \n",
      "11   0.158645    0.000000  0.421982   -1.677535  0.105989      -0.801513   \n",
      "12  -0.412478    0.000000  1.300556    0.221561 -0.723489       1.094539   \n",
      "13   1.491267    0.732828  0.042598    1.111763  0.658974       0.663618   \n",
      "14  -0.095187    0.732828  0.941140   -1.855576  0.797221      -1.663354   \n",
      "15  -0.602853    0.732828  0.402014    0.933723 -0.446997       0.318881   \n",
      "16   0.666311    0.000000  0.202338    0.162215 -0.446997      -0.025855   \n",
      "17   1.618183    0.000000 -0.117143    0.458948 -0.170504      -1.060065   \n",
      "18   0.349020    0.000000 -0.137111   -0.490600  1.488453      -0.112039   \n",
      "19  -0.285562    0.000000 -0.117143   -0.490600 -0.723489      -1.146249   \n",
      "20  -0.349020    0.732828 -0.855944    0.043521  0.244235      -0.801513   \n",
      "21  -0.475936    0.000000 -0.536463   -1.262108 -0.032257      -1.146249   \n",
      "22  -0.729769   -0.732828 -0.835977   -0.668640  0.797221       0.232697   \n",
      "23   0.158645   -1.465656  0.142436    0.399602  2.179684       0.491250   \n",
      "24   0.222104   -0.732828 -2.054001   -0.609294 -0.446997       0.146513   \n",
      "25  -0.602853   -0.732828 -1.135491   -0.787334  0.382482      -1.232433   \n",
      "26  -0.539394   -0.732828 -1.674616    1.171110  2.179684       0.577434   \n",
      "27   4.283426   -1.465656 -1.894260    0.933723  0.658974      -0.887697   \n",
      "28  -0.095187   -1.465656  0.162403   -0.490600  0.935467       0.577434   \n",
      "29   0.095187   -1.465656  0.721496   -1.024721 -1.276475      -1.232433   \n",
      "\n",
      "    Adj_Y_per_A_1  Y_per_C_1  Y_per_G_1  Pass_Effncy_Rate_1  ...  \\\n",
      "0        2.191188   1.107337   0.674336            2.219793  ...   \n",
      "1        0.013402  -0.432276   0.797950           -0.095748  ...   \n",
      "2       -0.154120  -0.609924   0.811470           -0.154369  ...   \n",
      "3       -0.053607  -0.432276   0.627981           -0.054713  ...   \n",
      "4        1.507698  -0.136197   1.840937            1.868065  ...   \n",
      "5        1.795836   1.462633   0.554586            1.703926  ...   \n",
      "6        1.762331   1.107337   0.921563            1.686339  ...   \n",
      "7       -0.763900   0.633610  -0.198683           -1.250588  ...   \n",
      "8       -1.132449  -1.202083  -0.177437           -0.810928  ...   \n",
      "9        0.810806   0.219099   0.272593            0.678053  ...   \n",
      "10       0.804106   0.870474   0.135460            0.859779  ...   \n",
      "11      -0.991730  -1.024435   0.044681           -0.869549  ...   \n",
      "12       1.052038   0.278315   0.915769            1.135299  ...   \n",
      "13       0.623182   0.633610  -1.523663            0.695639  ...   \n",
      "14      -1.869545  -2.208753  -0.604289           -1.332657  ...   \n",
      "15       0.549472   0.041451   1.049039            0.625294  ...   \n",
      "16       0.113915  -0.195412  -0.579180            0.138737  ...   \n",
      "17      -0.703592  -1.083651  -1.685905           -0.482649  ...   \n",
      "18      -0.482463  -0.017765  -0.951951           -0.365406  ...   \n",
      "19      -0.851012  -1.202083  -0.527030           -0.799204  ...   \n",
      "20      -0.656686  -0.313844  -0.156191           -0.705410  ...   \n",
      "21      -1.199457  -0.906003   0.394275           -1.233001  ...   \n",
      "22      -0.154120   0.811258   1.246048           -0.412303  ...   \n",
      "23       0.020103   0.455962  -0.088590            0.285290  ...   \n",
      "24       0.107214   1.758712  -0.884350           -0.658513  ...   \n",
      "25      -1.206158  -0.609924   0.685925           -1.315071  ...   \n",
      "26       0.221129   1.877144   0.373029            0.027357  ...   \n",
      "27      -0.629883   0.278315  -3.070760           -0.822652  ...   \n",
      "28       0.180924   0.515178  -0.758805            0.162186  ...   \n",
      "29      -0.904619  -1.675810  -0.138807           -0.722996  ...   \n",
      "\n",
      "    Int_per_Game_1  Rush_Att_per_Game_1  Rush_Yds_per_Game_1  \\\n",
      "0        -1.198844            -0.448553            -0.585679   \n",
      "1        -1.091028            -0.412467            -0.637068   \n",
      "2        -0.595074            -0.199750            -0.224937   \n",
      "3        -0.444132            -0.615980            -0.898567   \n",
      "4        -0.896959            -0.049708            -0.032315   \n",
      "5        -0.444132            -1.526575            -0.962485   \n",
      "6        -0.767580            -0.468714             0.535186   \n",
      "7         0.426690             0.988326             1.148110   \n",
      "8         1.216236             0.504877             0.106673   \n",
      "9        -1.500729             0.212391             1.160176   \n",
      "10        0.526213             0.660325             0.664928   \n",
      "11        0.426690            -0.284632            -0.236665   \n",
      "12       -0.618296            -0.628253            -0.720447   \n",
      "13       -0.444132             0.212391             0.001377   \n",
      "14        1.173109            -0.608091            -0.736783   \n",
      "15       -0.120684             0.071261            -0.054148   \n",
      "16       -0.618296             0.292160            -0.098128   \n",
      "17       -0.618296            -0.459949            -0.759244   \n",
      "18        0.775019            -1.241861            -0.296039   \n",
      "19       -0.618296             0.463970             0.110778   \n",
      "20        0.526213             0.451698            -0.441173   \n",
      "21        0.775019            -0.370537             0.467017   \n",
      "22        1.442649             1.655486             1.485958   \n",
      "23        1.820005             0.698257             0.643937   \n",
      "24       -0.821488             1.539458             1.397597   \n",
      "25        1.442649            -0.389503            -0.580111   \n",
      "26        2.197362             2.134100             1.556126   \n",
      "27       -1.061624             0.332044             0.227692   \n",
      "28        0.173360             0.625740             1.218278   \n",
      "29       -1.061624            -3.137910            -3.460045   \n",
      "\n",
      "    Rush_TD_per_Game_1  Rec_per_Game_1  Rcv_Yds_per_Game_1  Rcv_TD_per_Game_1  \\\n",
      "0            -0.146225        0.911173            0.410314          -0.334890   \n",
      "1            -0.146225       -0.610463           -0.601700          -0.245503   \n",
      "2            -0.146225       -0.474775           -0.556801          -0.245503   \n",
      "3             0.986404        1.336128            0.956340           1.439095   \n",
      "4            -0.146225        0.155201            0.076777           1.810394   \n",
      "5             0.080301       -0.705444           -0.689503           0.129921   \n",
      "6            -0.233350       -0.980993           -0.848837          -0.871211   \n",
      "7            -0.455123       -0.838664           -0.592629          -0.871211   \n",
      "8             0.684370       -0.759719           -0.637619          -0.871211   \n",
      "9             1.148208       -0.251861           -0.346558           0.737752   \n",
      "10           -0.407601       -1.356743           -1.000804          -0.871211   \n",
      "11            0.115151       -0.104245            0.178088           0.283942   \n",
      "12            0.115151       -0.980993           -0.761341          -0.293635   \n",
      "13            0.420090       -0.203401            0.036866           1.005913   \n",
      "14           -0.793441        0.504112            0.427418           0.737752   \n",
      "15           -0.059099       -0.855744           -0.775156          -0.871211   \n",
      "16           -0.756102       -0.041620           -0.245576          -0.293635   \n",
      "17           -1.278853       -0.717074           -0.363663          -0.334890   \n",
      "18           -0.756102        0.960379            1.200408           0.283942   \n",
      "19           -0.930352       -1.043618           -0.945543          -0.871211   \n",
      "20           -0.407601        1.398753            0.689248           0.283942   \n",
      "21           -0.059099        1.210878            0.606357           0.861518   \n",
      "22            0.986404       -0.616630           -0.783111          -0.871211   \n",
      "23            0.368607       -1.282732           -0.951823          -0.871211   \n",
      "24            2.016067        0.419527            0.425086          -0.188621   \n",
      "25            0.368607        0.493538            0.169296          -0.188621   \n",
      "26            0.780472       -0.394597           -0.652495          -0.871211   \n",
      "27            0.797633        1.628378            0.989727          -0.245503   \n",
      "28            1.398269        0.419527            0.599240          -0.871211   \n",
      "29           -3.544111        2.781720            3.987995           3.508745   \n",
      "\n",
      "    ScrmgPlays_per_Game_1  Scrmg_Yds_per_Game_1  Scrmg_TD_per_Game_1  \n",
      "0               -0.289982             -0.480207            -0.271933  \n",
      "1               -0.571482             -1.138946            -0.242274  \n",
      "2               -0.314461             -0.604742            -0.242274  \n",
      "3               -0.380364             -0.544458             1.562328  \n",
      "4               -0.020722              0.005357             0.439870  \n",
      "5               -1.788049             -1.591552             0.131422  \n",
      "6               -0.709878              0.159986            -0.545703  \n",
      "7                0.884972              1.065912            -0.789607  \n",
      "8                0.382352             -0.243715             0.463597  \n",
      "9                0.175104              1.225556             1.507574  \n",
      "10               0.423652              0.230431            -0.737342  \n",
      "11              -0.327641             -0.186817             0.220854  \n",
      "12              -0.881225             -1.335604             0.029215  \n",
      "13               0.185303              0.023387             0.795771  \n",
      "14              -0.547004             -0.656318            -0.627834  \n",
      "15              -0.103571             -0.522783            -0.354064  \n",
      "16               0.305026             -0.265390            -0.928981  \n",
      "17              -0.644917             -1.149429            -1.517587  \n",
      "18              -1.131656              0.341516            -0.737342  \n",
      "19               0.278665             -0.419826            -1.312260  \n",
      "20               0.779527             -0.138048            -0.354064  \n",
      "21              -0.143113              0.932166             0.220854  \n",
      "22               1.648247              1.370104             0.795771  \n",
      "23               0.479969              0.233387             0.116323  \n",
      "24               1.741709              1.972084             2.154667  \n",
      "25              -0.314461             -0.615149             0.342806  \n",
      "26               2.209020              1.533407             0.569289  \n",
      "27               0.699345              0.862851             0.795771  \n",
      "28               0.760355              1.853609             1.248737  \n",
      "29              -2.784720             -1.916771            -2.733584  \n",
      "\n",
      "[30 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78e82154421ec5c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:27.982016Z",
     "start_time": "2024-12-16T15:44:27.968428Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Create model\n",
    "def build_network(X):\n",
    "    #normal_layer = layers.Normalization(axis=-1)\n",
    "    #normal_layer.adapt(np.array(X.values))\n",
    "    #model.add(normal_layer)\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(10, activation = 'relu'),\n",
    "        layers.Dense(5, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "                           optimizer = tf.keras.optimizers.Adam(learning_rate = 0.1),\n",
    "                           metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d14fe9aff5765ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:44:28.107651Z",
     "start_time": "2024-12-16T15:44:28.094085Z"
    }
   },
   "outputs": [],
   "source": [
    "def leave_one_out_train(X, y):\n",
    "    callbacks =  [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'loss', \n",
    "        patience=3\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard()\n",
    "    ]\n",
    "\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for i in range(len(y)):\n",
    "        #print(y.shape)\n",
    "        y_train = np.asarray(y)\n",
    "        y_test = np.asarray(y[i])\n",
    "        y_train = np.delete(y_train, i)\n",
    "        X_train = X.copy()\n",
    "        X_test = pd.DataFrame(X.iloc[i,:]).transpose()\n",
    "        X_train.drop([i], inplace=True)\n",
    "        y_train = tf.convert_to_tensor(y_train, dtype='float')\n",
    "        y_test = tf.convert_to_tensor(y_test, dtype='float')\n",
    "        y_test = tf.reshape(y_test, [1,1])\n",
    "\n",
    "        my_model = build_network(X)\n",
    "        my_model.fit(X_train, y_train, epochs = 10, batch_size = 4, callbacks = callbacks)\n",
    "        error = my_model.evaluate(X_test, y_test)\n",
    "        losses.append(error[0])\n",
    "        accuracies.append(error[1])\n",
    "        print(f'Finished round {i+1}')\n",
    "    return losses, accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31b833e45930e4c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:45:17.457511Z",
     "start_time": "2024-12-16T15:44:28.220393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4757 - loss: 0.6956      \n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6987 - loss: 0.6105 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7047 - loss: 0.6251 \n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6806 - loss: 0.6678 \n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7690 - loss: 0.5467 \n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8075 - loss: 0.4968 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.2475\n",
      "Finished round 1\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6504 - loss: 0.9158  \n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7644 - loss: 0.6132 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7156 - loss: 0.5913 \n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7172 - loss: 0.6096 \n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6690 - loss: 0.6573 \n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7922 - loss: 0.5200 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.2220\n",
      "Finished round 2\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5362 - loss: 1.2749\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7698 - loss: 0.5569 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8200 - loss: 0.4898 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.2919\n",
      "Finished round 3\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6806 - loss: 0.6854  \n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.5881 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7605 - loss: 0.5509 \n",
      "WARNING:tensorflow:5 out of the last 104 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x0000025F337DAB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.2775\n",
      "Finished round 4\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5836 - loss: 0.7823\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7704 - loss: 0.5599 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7427 - loss: 0.5728 \n",
      "WARNING:tensorflow:6 out of the last 105 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x0000025F29F7E940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 1.0000 - loss: 0.2260\n",
      "Finished round 5\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5925 - loss: 0.8862\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7017 - loss: 0.6046 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8399 - loss: 0.4764 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 1.0000 - loss: 0.2623\n",
      "Finished round 6\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7350 - loss: 1.0956\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6018 - loss: 0.6713 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7866 - loss: 0.5425 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.1543\n",
      "Finished round 7\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7430 - loss: 0.6147\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7302 - loss: 0.5853 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8602 - loss: 0.4720 \n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.4348 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 1.0000 - loss: 0.2243\n",
      "Finished round 8\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7645 - loss: 0.6045\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7140 - loss: 0.6657 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8557 - loss: 0.4295 \n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4425 \n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8580 - loss: 0.4192 \n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7913 - loss: 0.5150 \n",
      "Epoch 7/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7427 - loss: 0.5805 \n",
      "Epoch 8/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.4556 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.0000e+00 - loss: 1.7319\n",
      "Finished round 9\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5749 - loss: 0.8993\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7869 - loss: 0.5245 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7823 - loss: 0.5286 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.3065\n",
      "Finished round 10\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5012 - loss: 0.7085    \n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8860 - loss: 0.2663 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8293 - loss: 0.4153 \n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8488 - loss: 0.2776 \n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8823 - loss: 0.2353 \n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9240 - loss: 0.1235 \n",
      "Epoch 7/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9782 - loss: 0.1013 \n",
      "Epoch 8/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9203 - loss: 0.1394 \n",
      "Epoch 9/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0360 \n",
      "Epoch 10/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9712 - loss: 0.0387 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 1.0000 - loss: 0.5858\n",
      "Finished round 11\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7991 - loss: 0.5584\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7767 - loss: 0.5416 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8380 - loss: 0.4464 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.3005\n",
      "Finished round 12\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4881 - loss: 0.6578      \n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8061 - loss: 0.5188 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7348 - loss: 0.5814 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.2605\n",
      "Finished round 13\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4164 - loss: 0.8253  \n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8065 - loss: 0.5531 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8582 - loss: 0.4539 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 1.0000 - loss: 0.2381\n",
      "Finished round 14\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8362 - loss: 0.7268\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6987 - loss: 0.6034 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7140 - loss: 0.6047 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.0000e+00 - loss: 1.8242\n",
      "Finished round 15\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4778 - loss: 0.8422\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8200 - loss: 0.4988 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7621 - loss: 0.5497 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 0.2421\n",
      "Finished round 16\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6663 - loss: 0.6461  \n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6505 - loss: 0.6482 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7797 - loss: 0.5511 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.1741\n",
      "Finished round 17\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5076 - loss: 0.7493  \n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7996 - loss: 0.5762 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7188 - loss: 0.6096 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 0.1857\n",
      "Finished round 18\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5429 - loss: 0.7268\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8712 - loss: 0.4531 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7936 - loss: 0.5139 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.0000e+00 - loss: 1.4950\n",
      "Finished round 19\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4206 - loss: 0.9401   \n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7232 - loss: 0.6091 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7737 - loss: 0.5448 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.2172\n",
      "Finished round 20\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7208 - loss: 0.7350\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8355 - loss: 0.4883 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8658 - loss: 0.3874 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.2763\n",
      "Finished round 21\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3042 - loss: 0.8915   \n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7950 - loss: 0.5662 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7235 - loss: 0.5867 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 0.2771\n",
      "Finished round 22\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5638 - loss: 0.9055\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.5831 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7903 - loss: 0.5314 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.2045\n",
      "Finished round 23\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6875 - loss: 0.8285\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8534 - loss: 0.5566 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7228 - loss: 0.5825 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.0000e+00 - loss: 1.6674\n",
      "Finished round 24\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5361 - loss: 0.7648\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8635 - loss: 0.4972 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8075 - loss: 0.4964 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.0000e+00 - loss: 1.8438\n",
      "Finished round 25\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5498 - loss: 0.6577  \n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.6270 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6871 - loss: 0.6116 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 1.0000 - loss: 0.2153\n",
      "Finished round 26\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4173 - loss: 0.8565\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6968 - loss: 0.6090 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6552 - loss: 0.6894 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.2003\n",
      "Finished round 27\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8186 - loss: 0.7700  \n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.5149 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8513 - loss: 0.4379 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.0000e+00 - loss: 1.8109\n",
      "Finished round 28\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7765 - loss: 0.7490\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8342 - loss: 0.4930 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8272 - loss: 0.4595 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.0000e+00 - loss: 1.3768\n",
      "Finished round 29\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4392 - loss: 0.6546   \n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7945 - loss: 0.5355 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7505 - loss: 0.5966 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 1.0000 - loss: 0.2576\n",
      "Finished round 30\n"
     ]
    }
   ],
   "source": [
    "loss_list, accuracy_list = leave_one_out_train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cfdd16be6f3c2973",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:45:17.644718Z",
     "start_time": "2024-12-16T15:45:17.620487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.5865769346555074\n",
      "Average Accuracy: 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(f'Average Loss: {np.average(loss_list)}')\n",
    "print(f'Average Accuracy: {np.average(accuracy_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2efd46fa8d588dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:45:19.733879Z",
     "start_time": "2024-12-16T15:45:17.819954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6550 - loss: 0.9900\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8025 - loss: 0.6187 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7567 - loss: 0.5812 \n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7692 - loss: 0.5475 \n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7817 - loss: 0.5298 \n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8358 - loss: 0.4550 \n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7567 - loss: 0.5688 \n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8233 - loss: 0.4707 \n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8025 - loss: 0.5018 \n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7692 - loss: 0.5450 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25f835630d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks =  [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'loss', \n",
    "        patience=3\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard()\n",
    "    ]\n",
    "final_model = build_network(X)\n",
    "y = tf.convert_to_tensor(y, dtype='float')\n",
    "final_model.fit(X, y, epochs = 10, batch_size = 8, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7bed2f9d521c",
   "metadata": {},
   "source": [
    "#### Python Package Import (same functionality as above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4629008ca682f5f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:45:20.834789Z",
     "start_time": "2024-12-16T15:45:20.805272Z"
    }
   },
   "outputs": [],
   "source": [
    "from qb_vs_rb import QBvsRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dce4ca40ca91173b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:45:21.206440Z",
     "start_time": "2024-12-16T15:45:21.196361Z"
    }
   },
   "outputs": [],
   "source": [
    "new_qbrb = QBvsRB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4350e02874b4aeff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:45:21.268384Z",
     "start_time": "2024-12-16T15:45:21.231172Z"
    }
   },
   "outputs": [],
   "source": [
    "new_qbrb.load_train_data('Heisman_Winner_QB_vs_RB_Singles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6a79b3b5dea4f6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:45:21.486943Z",
     "start_time": "2024-12-16T15:45:21.461238Z"
    }
   },
   "outputs": [],
   "source": [
    "new_qbrb.make_x_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f929b29c194caec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:46:10.905918Z",
     "start_time": "2024-12-16T15:45:21.628993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4401 - loss: 0.9041   \n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7565 - loss: 0.5934 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7288 - loss: 0.5816 \n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7079 - loss: 0.6217 \n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7364 - loss: 0.5960 \n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7292 - loss: 0.5952 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 1.0000 - loss: 0.3166\n",
      "Finished round 1\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2910 - loss: 0.8212\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7357 - loss: 0.5877 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8022 - loss: 0.5169 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.2032\n",
      "Finished round 2\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6521 - loss: 0.7457\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7288 - loss: 0.6022 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7667 - loss: 0.5561 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.2659\n",
      "Finished round 3\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7945 - loss: 0.4684\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6783 - loss: 0.6496 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7302 - loss: 0.6025 \n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7936 - loss: 0.5187 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.2173\n",
      "Finished round 4\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5995 - loss: 0.7522\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7130 - loss: 0.6352 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8274 - loss: 0.4812 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.2117\n",
      "Finished round 5\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6546 - loss: 0.6001\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7218 - loss: 0.5965 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7751 - loss: 0.5435 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.2163\n",
      "Finished round 6\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5734 - loss: 0.8609\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7348 - loss: 0.5822 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8114 - loss: 0.4979 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.2210\n",
      "Finished round 7\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7552 - loss: 0.6853  \n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7255 - loss: 0.5920 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6690 - loss: 0.6519 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 0.2431\n",
      "Finished round 8\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8742 - loss: 0.5948\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7427 - loss: 0.5853 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7606 - loss: 0.5584 \n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: 0.6559 \n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8409 - loss: 0.4813 \n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8080 - loss: 0.4949 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.0000e+00 - loss: 1.7946\n",
      "Finished round 9\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5740 - loss: 0.7375\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7982 - loss: 0.5397 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7459 - loss: 0.5928 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.2228\n",
      "Finished round 10\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7102 - loss: 0.6796\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7348 - loss: 0.8077 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8998 - loss: 0.2482 \n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9503 - loss: 0.1291 \n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8582 - loss: 0.2259 \n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9596 - loss: 0.1272 \n",
      "Epoch 7/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8684 - loss: 0.1457 \n",
      "Epoch 8/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9550 - loss: 0.0451     \n",
      "Epoch 9/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9675 - loss: 0.0281     \n",
      "Epoch 10/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9203 - loss: 0.0708 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.0000e+00 - loss: 0.7426\n",
      "Finished round 11\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6087 - loss: 0.5248\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6940 - loss: 0.6316 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6839 - loss: 0.6747 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.2425\n",
      "Finished round 12\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6267 - loss: 0.5306\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7973 - loss: 0.6032 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7985 - loss: 0.5245 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.2005\n",
      "Finished round 13\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8122 - loss: 0.5335\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7843 - loss: 0.5652 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7519 - loss: 0.5871 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.2849\n",
      "Finished round 14\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6389 - loss: 0.6480\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7682 - loss: 0.6358 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6423 - loss: 0.6429 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.0000e+00 - loss: 1.7997\n",
      "Finished round 15\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5925 - loss: 0.9935  \n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6880 - loss: 0.6583 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7212 - loss: 0.5918 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.2891\n",
      "Finished round 16\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5376 - loss: 0.8796\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8124 - loss: 0.5185 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7496 - loss: 0.5656 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 1.0000 - loss: 0.3322\n",
      "Finished round 17\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8038 - loss: 0.7368\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7281 - loss: 0.5839 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7635 - loss: 0.5482 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 1.0000 - loss: 0.2928\n",
      "Finished round 18\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6392 - loss: 0.7394\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7705 - loss: 0.5586 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7473 - loss: 0.5634 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.0000e+00 - loss: 1.7674\n",
      "Finished round 19\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.7514\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.5906 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7737 - loss: 0.5494 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.2681\n",
      "Finished round 20\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5443 - loss: 0.7226  \n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8121 - loss: 0.5405 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7102 - loss: 0.6618 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.2878\n",
      "Finished round 21\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5454 - loss: 0.7607\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6940 - loss: 0.6027 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7765 - loss: 0.5661 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.1709\n",
      "Finished round 22\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7200 - loss: 0.6529\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7670 - loss: 0.5597 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7829 - loss: 0.5266 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.2720\n",
      "Finished round 23\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7946 - loss: 0.8351\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.5686 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8154 - loss: 0.4907 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.0000e+00 - loss: 1.9830\n",
      "Finished round 24\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7188 - loss: 0.6116\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8455 - loss: 0.4546 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.4904 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.0000e+00 - loss: 1.6891\n",
      "Finished round 25\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5934 - loss: 0.6467\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7866 - loss: 0.6333 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7954 - loss: 0.5387 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.2708\n",
      "Finished round 26\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.6316\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7573 - loss: 0.5809 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7718 - loss: 0.5375 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.3017\n",
      "Finished round 27\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4594 - loss: 0.8215   \n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7360 - loss: 0.5802 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7774 - loss: 0.5331 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.0000e+00 - loss: 1.3847\n",
      "Finished round 28\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6593 - loss: 0.9214\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7691 - loss: 0.5874 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7629 - loss: 0.5465 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.0000e+00 - loss: 1.5627\n",
      "Finished round 29\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8457 - loss: 0.5710\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8401 - loss: 0.4689 \n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7903 - loss: 0.5619 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.4526\n",
      "Finished round 30\n",
      "Average Loss: 0.6169248128930728\n",
      "Average Accuracy: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "new_qbrb.leave_one_out_cross_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c294f57024c8a2e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:46:13.119632Z",
     "start_time": "2024-12-16T15:46:11.035059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3458 - loss: 0.8261   \n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7900 - loss: 0.5410 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8150 - loss: 0.4895 \n"
     ]
    }
   ],
   "source": [
    "new_qbrb.train_final_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1810bba6f2665bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T15:46:13.292134Z",
     "start_time": "2024-12-16T15:46:13.282013Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
