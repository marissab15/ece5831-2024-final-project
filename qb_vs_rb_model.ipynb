{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QB vs RB Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year          Best_QB  QB_Rank  QB_Games  Pass_Cmp  Pass_Att  Cmp%  \\\n",
      "0  2023  Jayden Daniels*        5        12       236       327  72.2   \n",
      "1  2022  Caleb Williams*        3        14       333       500  66.6   \n",
      "2  2021      Bryce Young        2        15       366       547  66.9   \n",
      "3  2020  Trevor Lawrence        8        10       231       334  69.2   \n",
      "4  2019      Joe Burrow*        1        15       402       527  76.3   \n",
      "\n",
      "   Pass_Yds  Pass_TD  Pass_TD%  ...  Int_per_Game  Rush_Att_per_Game  \\\n",
      "0      3812       40      12.2  ...      0.333333          20.357143   \n",
      "1      4537       42       8.4  ...      0.357143          20.583333   \n",
      "2      4872       47       8.6  ...      0.466667          21.916667   \n",
      "3      3153       24       7.2  ...      0.500000          19.307692   \n",
      "4      5671       60      11.4  ...      0.400000          22.857143   \n",
      "\n",
      "   Rush_Yds_per_Game  Rush_TD_per_Game  Rec_per_Game  Rcv_Yds_per_Game  \\\n",
      "0         123.714286               1.5      2.785714         23.571429   \n",
      "1         121.916667               1.5      0.916667          6.666667   \n",
      "2         136.333333               1.5      1.083333          7.416667   \n",
      "3         112.769231               2.0      3.307692         32.692308   \n",
      "4         143.071429               1.5      1.857143         18.000000   \n",
      "\n",
      "   Rcv_TD_per_Game ScrmgPlays_per_Game  Scrmg_Yds_per_Game  Scrmg_TD_per_Game  \n",
      "0         0.071429           23.142857          147.285714           1.571429  \n",
      "1         0.083333           21.500000          128.583333           1.583333  \n",
      "2         0.083333           23.000000          143.750000           1.583333  \n",
      "3         0.307692           22.615385          145.461538           2.307692  \n",
      "4         0.357143           24.714286          161.071429           1.857143  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "input_df = pd.read_csv('Heisman_Winner_QB_vs_RB_Import.csv')\n",
    "#print(input_data_cv.head())\n",
    "\n",
    "#Standardize stats by # of games played\n",
    "input_df['Pass_Cmp_per_Game'] = input_df['Pass_Cmp']/input_df['QB_Games']\n",
    "input_df['Pass_Att_per_Game'] = input_df['Pass_Att']/input_df['QB_Games']\n",
    "input_df['Pass_TD_per_Game'] = input_df['Pass_TD']/input_df['QB_Games']\n",
    "input_df['Int_per_Game'] = input_df['Int']/input_df['QB_Games']\n",
    "\n",
    "input_df['Rush_Att_per_Game'] = input_df['Rush_Att']/input_df['RB_Games']\n",
    "input_df['Rush_Yds_per_Game'] = input_df['Rush_Yds']/input_df['RB_Games']\n",
    "input_df['Rush_TD_per_Game'] = input_df['Rush_TD']/input_df['RB_Games']\n",
    "input_df['Rec_per_Game'] = input_df['Rec']/input_df['RB_Games']\n",
    "input_df['Rcv_Yds_per_Game'] = input_df['Rcv_Yds']/input_df['RB_Games']\n",
    "input_df['Rcv_TD_per_Game'] = input_df['Rcv_TD']/input_df['RB_Games']\n",
    "input_df['ScrmgPlays_per_Game'] = input_df['ScrmgPlays']/input_df['RB_Games']\n",
    "input_df['Scrmg_Yds_per_Game'] = input_df['Scrmg_Yds']/input_df['RB_Games']\n",
    "input_df['Scrmg_TD_per_Game'] = input_df['Scrmg_TD']/input_df['RB_Games']\n",
    "print(input_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the quarterback and running back datasets, which have 1 entry per player per year, the Heisman winner dataset is much smaller, with only 30 entries of data. Due to the limited dataset size, instead of creating a traditional train and test set, I will be evaluating the performance of my model using leave-one-out cross-validation. This method is most commonly used on very small datasets.\n",
    "\n",
    "In this process, I will create 30 models, each one leaving exactly one year of data out for testing. After training each model, I will record the error (cross-entropy) of the one test record, then average all 30 errors to estimate the test error of a model trained on all 30 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop non-standardized variables\n",
    "vars_final = input_df.drop(columns = ['Pass_Cmp','Pass_Att','Pass_Yds', 'Pass_TD', 'Int', 'Rush_Att', 'Rush_Yds', 'Rush_TD',\n",
    "                                      'Rec','Rcv_Yds','Rcv_TD','ScrmgPlays','Scrmg_Yds','Scrmg_TD'])\n",
    "\n",
    "#Drop variables we won't be using to predict\n",
    "vars_final.drop(columns = ['Year','Best_QB','QB_Games', 'Best_RB', 'RB_Games'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X and y tensors\n",
    "X = vars_final.drop(columns = ['Winner'])\n",
    "y = pd.Series([1 if winner == 'QB' else 0 for winner in vars_final['Winner']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.array([[1,2,3,4,5], [1, 7, 2, 8, 5]])\n",
    "#normal_layer = layers.Normalization(axis=-1)\n",
    "#normal_layer.adapt(x)\n",
    "#y = normal_layer(x)\n",
    "\n",
    "#Create model\n",
    "def build_network(X):\n",
    "    normal_layer = layers.Normalization(axis=-1)\n",
    "    normal_layer.adapt(np.array(X.values))\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(normal_layer)\n",
    "    model.add(layers.Dense(10, activation = 'relu'))\n",
    "    model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "                           optimizer = 'rmsprop',\n",
    "                           metrics = ['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_model = build_network(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_train(X, y):\n",
    "    callbacks =  [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss', \n",
    "        patience=3\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard()\n",
    "    ]\n",
    "\n",
    "    errors = []\n",
    "    for i in range(len(y)):\n",
    "        y_train = y.copy()\n",
    "        y_test = y_train.pop(i)\n",
    "        X_train = X.copy()\n",
    "        X_test = X[i]\n",
    "        X_train.drop(i)\n",
    "\n",
    "        my_first_model.fit(X_train, y_train, epochs = 10, callbacks = callbacks)\n",
    "        error = my_first_model.evaluate(X_test, y_test)\n",
    "        errors.append(error)\n",
    "        print(f'Finished round {i}')\n",
    "    return errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/ece5831-2024/ece-5831-2024/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m error_list \u001b[38;5;241m=\u001b[39m \u001b[43mleave_one_out_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[110], line 15\u001b[0m, in \u001b[0;36mleave_one_out_train\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m y_test \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mpop(i)\n\u001b[1;32m     14\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 15\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     16\u001b[0m X_train\u001b[38;5;241m.\u001b[39mdrop(i)\n\u001b[1;32m     18\u001b[0m my_first_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, callbacks \u001b[38;5;241m=\u001b[39m callbacks)\n",
      "File \u001b[0;32m~/ece5831-2024/ece-5831-2024/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/ece5831-2024/ece-5831-2024/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "error_list = leave_one_out_train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece-5831-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
