{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['RB_DATA_1993.csv', 'RB_DATA_1994.csv', 'RB_DATA_1995.csv', 'RB_DATA_1996.csv', 'RB_DATA_1997.csv', 'RB_DATA_1998.csv', 'RB_DATA_1999.csv', 'RB_DATA_2000.csv', 'RB_DATA_2002.csv', 'RB_DATA_2003.csv', 'RB_DATA_2004.csv', 'RB_DATA_2005.csv', 'RB_DATA_2006.csv', 'RB_DATA_2007.csv', 'RB_DATA_2008.csv', 'RB_DATA_2009.csv','RB_DATA_2010.csv', 'RB_DATA_2011.csv', 'RB_DATA_2012.csv', 'RB_DATA_2013.csv', 'RB_DATA_2014.csv', 'RB_DATA_2015.csv','RB_DATA_2016.csv', 'RB_DATA_2017.csv', 'RB_DATA_2018.csv', 'RB_DATA_2019.csv', 'RB_DATA_2020.csv', 'RB_DATA_2021.csv', 'RB_DATA_2022.csv', 'RB_DATA_2023.csv' ]  # List to store datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_names_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step\n",
      "Data for year 1995:\n",
      "                  Player  Actual Heisman  Predicted Probability\n",
      "0             Troy Davis               0               0.709423\n",
      "1            Wasean Tait               0               0.514548\n",
      "2           George Jones               0               0.446509\n",
      "3           Eddie George               1               0.347616\n",
      "4  Tshimanga Biakabutuka               0               0.661182\n",
      "Actual Heisman Winner for 1995: Eddie George\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Data for year 2000:\n",
      "                Player  Actual Heisman  Predicted Probability\n",
      "0  LaDainian Tomlinson               1               0.464836\n",
      "1      Damien Anderson               0               0.464836\n",
      "2      Michael Bennett               0               0.464836\n",
      "3      Deonce Whitaker               0               0.464836\n",
      "4       Robert Sanford               0               0.464836\n",
      "Actual Heisman Winner for 2000: LaDainian Tomlinson\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Data for year 2005:\n",
      "               Player  Actual Heisman  Predicted Probability\n",
      "0  DeAngelo Williams*               0               0.467303\n",
      "1     Jerome Harrison               0               0.467303\n",
      "2        Reggie Bush*               1               0.467303\n",
      "3      Brian Calhoun*               0               0.467303\n",
      "4       Garrett Wolfe               0               0.467303\n",
      "Actual Heisman Winner for 2005: Reggie Bush*\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000297A529B400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Data for year 2010:\n",
      "             Player  Actual Heisman  Predicted Probability\n",
      "0  LaMichael James*               1               0.435025\n",
      "1  Denard Robinson*               0               0.435025\n",
      "2   Mikel Leshoure*               0               0.435025\n",
      "3    Jordan Todman*               0               0.435025\n",
      "4      Bobby Rainey               0               0.435025\n",
      "Actual Heisman Winner for 2010: LaMichael James*\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000297A529A4D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "Data for year 2015:\n",
      "                 Player  Actual Heisman  Predicted Probability\n",
      "0        Derrick Henry*               1               0.413351\n",
      "1  Christian McCaffrey*               0               0.413351\n",
      "2    Leonard Fournette*               0               0.413351\n",
      "3        Royce Freeman*               0               0.413351\n",
      "4      Ezekiel Elliott*               0               0.413351\n",
      "Actual Heisman Winner for 2015: Derrick Henry*\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Data for year 2020:\n",
      "               Player  Actual Heisman  Predicted Probability\n",
      "0        Breece Hall*               0               0.371578\n",
      "1  Sincere McCormick*               0               0.371578\n",
      "2       Najee Harris*               1               0.371578\n",
      "3     Michael Carter*               0               0.371578\n",
      "4      Khalil Herbert               0               0.371578\n",
      "Actual Heisman Winner for 2020: Najee Harris*\n",
      "   Year                                  Predicted Winners  \\\n",
      "0  1995         Byron Hanspard, Troy Davis, Charles Talley   \n",
      "1  2000  LaDainian Tomlinson, Damien Anderson, Michael ...   \n",
      "2  2005  DeAngelo Williams*, Jerome Harrison, Reggie Bush*   \n",
      "3  2010  LaMichael James*, Denard Robinson*, Mikel Lesh...   \n",
      "4  2015  Derrick Henry*, Christian McCaffrey*, Leonard ...   \n",
      "5  2020    Breece Hall*, Sincere McCormick*, Najee Harris*   \n",
      "\n",
      "         Actual Winner Match  \n",
      "0         Eddie George    No  \n",
      "1  LaDainian Tomlinson   Yes  \n",
      "2         Reggie Bush*   Yes  \n",
      "3     LaMichael James*   Yes  \n",
      "4       Derrick Henry*   Yes  \n",
      "5        Najee Harris*   Yes  \n"
     ]
    }
   ],
   "source": [
    "# Lists to store training and testing results\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "# Loop through datasets\n",
    "for dataset in datasets:\n",
    "    # Extract the year from the dataset name\n",
    "    year = dataset.split('_')[-1].split('.')[0]\n",
    "    file_path = os.path.join(folder_path, dataset)\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Ensure 'Awards' column exists and clean it\n",
    "    if 'Awards' not in df.columns:\n",
    "        print(f\"Warning: 'Awards' column not found in {dataset}. Skipping this dataset.\")\n",
    "        continue\n",
    "    \n",
    "    df['Awards'] = df['Awards'].fillna(0).astype(int)  # Clean 'Awards' column\n",
    "\n",
    "    # Check for Heisman winner (only one should be present)\n",
    "    heisman_winners = df[df['Awards'] == 1]\n",
    "    if len(heisman_winners) != 1:\n",
    "        print(f\"Warning: More than one or no Heisman winner found in {year} dataset!\")\n",
    "        continue  # Skip this dataset if there's no valid Heisman winner\n",
    "    \n",
    "    # Track player names\n",
    "    player_names_all.append(df['Player'].values)\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = df.drop(['Awards', 'Player'], axis=1).select_dtypes(include=['number'])\n",
    "    y = df['Awards']\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Check if this year should be used for testing or training\n",
    "    if year[-1] in ['0', '5']:  # Testing set for years ending in '0' or '5'\n",
    "        # Split data into test set\n",
    "        X_test = X\n",
    "        y_test = y\n",
    "\n",
    "        # Scale the data for testing\n",
    "        scaler = StandardScaler()\n",
    "        X_test_scaled = scaler.fit_transform(X_test)\n",
    "        \n",
    "        # Build the model\n",
    "        model = tf.keras.Sequential([ \n",
    "            tf.keras.layers.Dense(16, activation='relu', input_shape=(X_test_scaled.shape[1],)), \n",
    "            tf.keras.layers.Dense(16, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid') \n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model on the training set from previous years\n",
    "        if len(train_results) > 0:\n",
    "            X_train_scaled = np.concatenate([result['X_train_scaled'] for result in train_results], axis=0)\n",
    "            y_train = np.concatenate([result['y_train'] for result in train_results], axis=0)\n",
    "            model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "        \n",
    "        # Predict on the test set and get probabilities\n",
    "        y_pred_prob = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Retrieve player names for the test set\n",
    "        test_player_names = df.loc[X_test.index, 'Player'].values\n",
    "\n",
    "        # Prepare the test data for comparison\n",
    "        test_data = X_test.copy()\n",
    "        test_data['Actual Heisman'] = y_test.values  # Correctly assign actual Heisman winners\n",
    "        test_data['Player'] = test_player_names\n",
    "        test_data['Predicted Probability'] = y_pred_prob\n",
    "\n",
    "        # Debugging: Print data to check 'Awards' column and ensure it's being processed\n",
    "        print(f\"Data for year {year}:\")\n",
    "        print(test_data[['Player', 'Actual Heisman', 'Predicted Probability']].head())  # Debugging output\n",
    "        \n",
    "        # Sort by predicted probability to get the top 3 predicted winners\n",
    "        top_3_predicted = test_data.nlargest(3, 'Predicted Probability')[['Player', 'Predicted Probability']]\n",
    "\n",
    "        # Get player statistics for the top 3 by looking them up in the original dataset\n",
    "        top_3_stats = df[df['Player'].isin(top_3_predicted['Player'].values)][[\n",
    "            'Player', 'Team', 'Conf', 'G', 'Att', 'Yds', 'Y/A', 'TD', 'Y/G', 'Rec', 'Yds.1', \n",
    "            'Y/R', 'TD.1', 'Y/G.1', 'Plays', 'Yds.2', 'Avg', 'TD.2'\n",
    "        ]]\n",
    "\n",
    "        # Add a custom identifier with format 'player-name-id'\n",
    "        # We now exclude the 'Awards' column and simply use the player's name and an optional identifier\n",
    "        top_3_stats['-9999'] = top_3_stats['Player'].str.lower().str.replace(' ', '-')  # Custom identifier\n",
    "        \n",
    "        # Save the top 3 players and their stats for this year in the same format as the original CSV\n",
    "        output_file_path = os.path.join('DATA', f'top_3_players_{year}.csv')\n",
    "        top_3_stats.to_csv(output_file_path, index=False)\n",
    "\n",
    "        # Check if there is at least one actual Heisman winner\n",
    "        actual_winner = test_data[test_data['Actual Heisman'] == 1]\n",
    "        \n",
    "        if actual_winner.empty:\n",
    "            print(f\"Warning: No actual Heisman winner found for {year}. Skipping this dataset.\")\n",
    "            continue  # Skip this year if there's no actual winner\n",
    "\n",
    "        # If there's an actual winner, get the name\n",
    "        actual_winner_name = actual_winner['Player'].values[0]\n",
    "        print(f\"Actual Heisman Winner for {year}: {actual_winner_name}\")  # Debugging check\n",
    "        \n",
    "        # Check if one of the predicted winners matches the actual winner\n",
    "        predicted_winners = top_3_predicted['Player'].values\n",
    "        match = 'Yes' if actual_winner_name in predicted_winners else 'No'\n",
    "\n",
    "        # Store the test results for this year\n",
    "        test_results.append({\n",
    "            'Year': year,\n",
    "            'Predicted Winners': ', '.join(predicted_winners),\n",
    "            'Actual Winner': actual_winner_name,\n",
    "            'Match': match\n",
    "        })\n",
    "\n",
    "    else:  # Training set for all other years\n",
    "        # Split data into training set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Scale the data for training\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        # Store training results for later use\n",
    "        train_results.append({\n",
    "            'X_train_scaled': X_train_scaled,\n",
    "            'y_train': y_train\n",
    "        })\n",
    "        \n",
    "# Convert results to DataFrame for better readability\n",
    "test_results_df = pd.DataFrame(test_results)\n",
    "\n",
    "# Output the results for test set\n",
    "print(test_results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece5831-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
