{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#where the csv files are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'DATA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#all csv files for RBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['RB_DATA_1993.csv', 'RB_DATA_1994.csv', 'RB_DATA_1995.csv', 'RB_DATA_1996.csv', 'RB_DATA_1997.csv', 'RB_DATA_1998.csv', 'RB_DATA_1999.csv', 'RB_DATA_2000.csv', 'RB_DATA_2002.csv', 'RB_DATA_2003.csv', 'RB_DATA_2004.csv', 'RB_DATA_2005.csv', 'RB_DATA_2006.csv', 'RB_DATA_2007.csv', 'RB_DATA_2008.csv', 'RB_DATA_2009.csv','RB_DATA_2010.csv', 'RB_DATA_2011.csv', 'RB_DATA_2012.csv', 'RB_DATA_2013.csv', 'RB_DATA_2014.csv', 'RB_DATA_2015.csv','RB_DATA_2016.csv', 'RB_DATA_2017.csv', 'RB_DATA_2018.csv', 'RB_DATA_2019.csv', 'RB_DATA_2020.csv', 'RB_DATA_2021.csv', 'RB_DATA_2022.csv', 'RB_DATA_2023.csv' ]  # List to store datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#list to store player names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_names_all = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Lists to store training and testing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = []\n",
    "test_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create an empty set to store all unique teams and conferences across datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teams = set()\n",
    "all_confs = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#collecting a full set of unique teams and conferences to use them for one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First pass through datasets to collect all unique teams and conferences\n",
    "for dataset in datasets:\n",
    "    file_path = os.path.join(folder_path, dataset)\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Collect all unique teams and conferences\n",
    "    all_teams.update(df['Team'].unique())\n",
    "    all_confs.update(df['Conf'].unique())\n",
    "\n",
    "all_teams = sorted(list(all_teams))\n",
    "all_confs = sorted(list(all_confs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Loop through datasets to process them, lots of code in the loop so it is commented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predicted probabilities for year 1995:\n",
      "[[0.25778514]\n",
      " [0.25778514]\n",
      " [0.25778514]\n",
      " [0.25778514]\n",
      " [0.25778514]\n",
      " [0.25778514]\n",
      " [0.25778514]\n",
      " [0.25778514]\n",
      " [0.25778514]\n",
      " [0.25778514]]\n",
      "Data for year 1995:\n",
      "                  Player  Actual Heisman  Predicted Probability\n",
      "0             Troy Davis               0               0.257785\n",
      "1            Wasean Tait               0               0.257785\n",
      "2           George Jones               0               0.257785\n",
      "3           Eddie George               1               0.257785\n",
      "4  Tshimanga Biakabutuka               0               0.257785\n",
      "Actual Heisman Winner for 1995: Eddie George\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Predicted probabilities for year 2000:\n",
      "[[0.05365385]\n",
      " [0.05365385]\n",
      " [0.05365385]\n",
      " [0.05365385]\n",
      " [0.05365385]\n",
      " [0.05365385]\n",
      " [0.05365385]\n",
      " [0.05365385]\n",
      " [0.05365385]\n",
      " [0.05365385]]\n",
      "Data for year 2000:\n",
      "                Player  Actual Heisman  Predicted Probability\n",
      "0  LaDainian Tomlinson               1               0.053654\n",
      "1      Damien Anderson               0               0.053654\n",
      "2      Michael Bennett               0               0.053654\n",
      "3      Deonce Whitaker               0               0.053654\n",
      "4       Robert Sanford               0               0.053654\n",
      "Actual Heisman Winner for 2000: LaDainian Tomlinson\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "Predicted probabilities for year 2005:\n",
      "[[0.04988991]\n",
      " [0.04988991]\n",
      " [0.04988991]\n",
      " [0.04988991]\n",
      " [0.04988991]\n",
      " [0.04988991]\n",
      " [0.04988991]\n",
      " [0.04988991]\n",
      " [0.04988991]\n",
      " [0.04988991]]\n",
      "Data for year 2005:\n",
      "               Player  Actual Heisman  Predicted Probability\n",
      "0  DeAngelo Williams*               0                0.04989\n",
      "1     Jerome Harrison               0                0.04989\n",
      "2        Reggie Bush*               1                0.04989\n",
      "3      Brian Calhoun*               0                0.04989\n",
      "4       Garrett Wolfe               0                0.04989\n",
      "Actual Heisman Winner for 2005: Reggie Bush*\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "Predicted probabilities for year 2010:\n",
      "[[0.04531657]\n",
      " [0.04531657]\n",
      " [0.04531657]\n",
      " [0.04531657]\n",
      " [0.04531657]\n",
      " [0.04531657]\n",
      " [0.04531657]\n",
      " [0.04531657]\n",
      " [0.04531657]\n",
      " [0.04531657]]\n",
      "Data for year 2010:\n",
      "             Player  Actual Heisman  Predicted Probability\n",
      "0  LaMichael James*               1               0.045317\n",
      "1  Denard Robinson*               0               0.045317\n",
      "2   Mikel Leshoure*               0               0.045317\n",
      "3    Jordan Todman*               0               0.045317\n",
      "4      Bobby Rainey               0               0.045317\n",
      "Actual Heisman Winner for 2010: LaMichael James*\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D59E71B640> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Predicted probabilities for year 2015:\n",
      "[[0.04692169]\n",
      " [0.04692169]\n",
      " [0.04692169]\n",
      " [0.04692169]\n",
      " [0.04692169]\n",
      " [0.04692169]\n",
      " [0.04692169]\n",
      " [0.04692169]\n",
      " [0.04692169]\n",
      " [0.04692169]]\n",
      "Data for year 2015:\n",
      "                 Player  Actual Heisman  Predicted Probability\n",
      "0        Derrick Henry*               1               0.046922\n",
      "1  Christian McCaffrey*               0               0.046922\n",
      "2    Leonard Fournette*               0               0.046922\n",
      "3        Royce Freeman*               0               0.046922\n",
      "4      Ezekiel Elliott*               0               0.046922\n",
      "Actual Heisman Winner for 2015: Derrick Henry*\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D59C38FD00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "Predicted probabilities for year 2020:\n",
      "[[0.04643889]\n",
      " [0.04643889]\n",
      " [0.04643889]\n",
      " [0.04643889]\n",
      " [0.04643889]\n",
      " [0.04643889]\n",
      " [0.04643889]\n",
      " [0.04643889]\n",
      " [0.04643889]\n",
      " [0.04643889]]\n",
      "Data for year 2020:\n",
      "               Player  Actual Heisman  Predicted Probability\n",
      "0        Breece Hall*               0               0.046439\n",
      "1  Sincere McCormick*               0               0.046439\n",
      "2       Najee Harris*               1               0.046439\n",
      "3     Michael Carter*               0               0.046439\n",
      "4      Khalil Herbert               0               0.046439\n",
      "Actual Heisman Winner for 2020: Najee Harris*\n",
      "   Year                                  Predicted Winners  \\\n",
      "0  1995              Troy Davis, Wasean Tait, George Jones   \n",
      "1  2000  LaDainian Tomlinson, Damien Anderson, Michael ...   \n",
      "2  2005  DeAngelo Williams*, Jerome Harrison, Reggie Bush*   \n",
      "3  2010  LaMichael James*, Denard Robinson*, Mikel Lesh...   \n",
      "4  2015  Derrick Henry*, Christian McCaffrey*, Leonard ...   \n",
      "5  2020    Breece Hall*, Sincere McCormick*, Najee Harris*   \n",
      "\n",
      "         Actual Winner Match  \n",
      "0         Eddie George    No  \n",
      "1  LaDainian Tomlinson   Yes  \n",
      "2         Reggie Bush*   Yes  \n",
      "3     LaMichael James*   Yes  \n",
      "4       Derrick Henry*   Yes  \n",
      "5        Najee Harris*   Yes  \n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    # Extract the year from the dataset name\n",
    "    year = dataset.split('_')[-1].split('.')[0]\n",
    "    file_path = os.path.join(folder_path, dataset)\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Ensure 'Awards' column exists and clean it\n",
    "    if 'Awards' not in df.columns:\n",
    "        print(f\"Warning: 'Awards' column not found in {dataset}. Skipping this dataset.\")\n",
    "        continue\n",
    "    \n",
    "    df['Awards'] = df['Awards'].fillna(0).astype(int)  # Clean 'Awards' column\n",
    "\n",
    "    # Check for Heisman winner (only one should be present)\n",
    "    heisman_winners = df[df['Awards'] == 1]\n",
    "    if len(heisman_winners) != 1:\n",
    "        print(f\"Warning: More than one or no Heisman winner found in {year} dataset!\")\n",
    "        continue  # Skip this dataset if there's no valid Heisman winner\n",
    "    \n",
    "    # Track player names\n",
    "    player_names_all.append(df['Player'].values)\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = df.drop(['Awards', 'Player'], axis=1).select_dtypes(include=['number'])\n",
    "    y = df['Awards']\n",
    "\n",
    "    # One-Hot Encoding for 'Team' and 'Conf', ensuring consistency across datasets\n",
    "    X_encoded = pd.concat([\n",
    "        X,\n",
    "        pd.get_dummies(df['Team'], prefix='Team').reindex(columns=all_teams, fill_value=0),\n",
    "        pd.get_dummies(df['Conf'], prefix='Conf').reindex(columns=all_confs, fill_value=0)\n",
    "    ], axis=1)\n",
    "\n",
    "    # Reset index for consistency\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Check if this year should be used for testing or training\n",
    "    if year[-1] in ['0', '5']:  # Testing set for years ending in '0' or '5'\n",
    "        # Split data into test set\n",
    "        X_test = X_encoded\n",
    "        y_test = y\n",
    "\n",
    "        # Scale the data for testing\n",
    "        scaler = StandardScaler()\n",
    "        X_test_scaled = scaler.fit_transform(X_test)\n",
    "        \n",
    "        # Build the model\n",
    "        model = tf.keras.Sequential([ \n",
    "            tf.keras.layers.Dense(128, activation='relu', input_shape=(X_test_scaled.shape[1],)),  # Increased complexity\n",
    "            tf.keras.layers.Dropout(0.2),  # Add dropout to prevent overfitting\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),  # Add dropout here as well\n",
    "            tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid') \n",
    "        ])\n",
    "\n",
    "        # Compile the model with adjusted learning rate and class weight\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  # Adjust learning rate\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model on the training set from previous years\n",
    "        if len(train_results) > 0:\n",
    "            X_train_scaled = np.concatenate([result['X_train_scaled'] for result in train_results], axis=0)\n",
    "            y_train = np.concatenate([result['y_train'] for result in train_results], axis=0)\n",
    "            \n",
    "            model.fit(X_train_scaled, y_train, epochs=30, batch_size=32, verbose=0)\n",
    "\n",
    "            # Predict on the test set and get probabilities\n",
    "            y_pred_prob = model.predict(X_test_scaled)\n",
    "\n",
    "            # Debugging: Print out the predicted probabilities to check for improvement\n",
    "            print(f\"Predicted probabilities for year {year}:\")\n",
    "            print(y_pred_prob[:10])  # Display first 10 predictions\n",
    "                    \n",
    "        # Retrieve player names for the test set\n",
    "        test_player_names = df.loc[X_test.index, 'Player'].values\n",
    "\n",
    "        # Prepare the test data for comparison\n",
    "        test_data = X_test.copy()\n",
    "        test_data['Actual Heisman'] = y_test.values\n",
    "        test_data['Player'] = test_player_names\n",
    "        test_data['Predicted Probability'] = y_pred_prob\n",
    "\n",
    "        print(f\"Data for year {year}:\")\n",
    "        print(test_data[['Player', 'Actual Heisman', 'Predicted Probability']].head()) \n",
    "\n",
    "        # Sort by predicted probability to get the top 3 predicted winners\n",
    "        top_3_predicted = test_data.nlargest(3, 'Predicted Probability')[['Player', 'Predicted Probability']]\n",
    "\n",
    "        # Get player statistics for the top 3 by looking them up in the original dataset\n",
    "        top_3_stats = df[df['Player'].isin(top_3_predicted['Player'].values)][[\n",
    "            'Player', 'Team', 'Conf', 'G', 'Att', 'Yds', 'Y/A', 'TD', 'Y/G', 'Rec', 'Yds.1', \n",
    "            'Y/R', 'TD.1', 'Y/G.1', 'Plays', 'Yds.2', 'Avg', 'TD.2'\n",
    "        ]]\n",
    "\n",
    "        # Add a custom identifier with format 'player-name-id'\n",
    "        top_3_stats['-9999'] = top_3_stats['Player'].str.lower().str.replace(' ', '-')\n",
    "        \n",
    "        # Save the top 3 players and their stats for this year in the same format as the original CSV\n",
    "        output_file_path = os.path.join('DATA', f'top_3_players_{year}.csv')\n",
    "        top_3_stats.to_csv(output_file_path, index=False)\n",
    "\n",
    "        # Check if there is at least one actual Heisman winner\n",
    "        actual_winner = test_data[test_data['Actual Heisman'] == 1]\n",
    "        \n",
    "        if actual_winner.empty:\n",
    "            print(f\"Warning: No actual Heisman winner found for {year}. Skipping this dataset.\")\n",
    "            continue  # Skip this year if there's no actual winner\n",
    "\n",
    "        # If there's an actual winner, get the name\n",
    "        actual_winner_name = actual_winner['Player'].values[0]\n",
    "        print(f\"Actual Heisman Winner for {year}: {actual_winner_name}\")  \n",
    "\n",
    "        # Check if one of the predicted winners matches the actual winner\n",
    "        predicted_winners = top_3_predicted['Player'].values\n",
    "        match = 'Yes' if actual_winner_name in predicted_winners else 'No'\n",
    "\n",
    "        # Store the test results for this year\n",
    "        test_results.append({\n",
    "            'Year': year,\n",
    "            'Predicted Winners': ', '.join(predicted_winners),\n",
    "            'Actual Winner': actual_winner_name,\n",
    "            'Match': match\n",
    "        })\n",
    "\n",
    "    else:  # Training set for all other years\n",
    "        # Use the entire dataset as the training set\n",
    "        X_train = X_encoded\n",
    "        y_train = y\n",
    "        \n",
    "        # Scale the data for training\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        # Store training results for later use\n",
    "        train_results.append({\n",
    "            'X_train_scaled': X_train_scaled,\n",
    "            'y_train': y_train\n",
    "        })\n",
    "        \n",
    "test_results_df = pd.DataFrame(test_results)\n",
    "\n",
    "#printing top 3 from each test year\n",
    "print(test_results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece5831-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
